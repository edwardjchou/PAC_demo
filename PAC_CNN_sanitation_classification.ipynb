{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from keras import applications\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Input\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import color\n",
    "from skimage.transform import resize\n",
    "\n",
    "from IPython.display import Audio\n",
    "from IPython.display import display\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25740\n",
      "8580\n",
      "8580\n",
      "['02' '04' '06' '08' '11' '15' '23' '39' '52' '59' '62' '63' '72']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(len(np.load('pac_arrays/train_all.npy')))\n",
    "print(len(np.load('pac_arrays/test_all.npy')))\n",
    "print(len(np.load('pac_arrays/dev_all.npy')))\n",
    "\n",
    "print(np.load('sub_dirs.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112036\n",
      "['0', '0', '0', '0', '0']\n",
      "{'23': 6, '62': 10, '52': 8, '72': 12, '39': 7, '59': 9, '63': 11, '06': 2, '02': 0, '04': 1, '15': 5, '11': 4, '08': 3}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open(\"pac_guide.csv\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    i = 0\n",
    "    image_paths = []\n",
    "    camera_nums = []\n",
    "    sanitation_labels = []\n",
    "    labels = []\n",
    "    \n",
    "    for row in reader:\n",
    "        index = row[0]\n",
    "        camera_num = row[1]\n",
    "        label = row[2]\n",
    "        filename = row[3]\n",
    "        image_paths.append(filename)\n",
    "        labels.append(label)\n",
    "        #camera_nums.append(camera_num)\n",
    "        sanitation_labels.append(label)\n",
    "        #print(index, camera_num, label, filename)\n",
    "print(len(image_paths)) # number of rows: 112036\n",
    "#print(len(camera_nums))\n",
    "print(sanitation_labels[0:5])\n",
    "\n",
    "sub_dir_hash = {}\n",
    "for i, sub_dir in enumerate(np.load('sub_dirs.npy')):\n",
    "    sub_dir_hash[sub_dir] = i\n",
    "\n",
    "print(sub_dir_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def depth_map_to_image(depth_map):\n",
    "    img = cv2.normalize(depth_map, depth_map, 0, 1, cv2.NORM_MINMAX)\n",
    "    img = np.array(img * 255, dtype=np.uint8)\n",
    "    orig_img = img\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    img = cv2.applyColorMap(img, cv2.COLORMAP_OCEAN)\n",
    "    #img = resize(img, 224, 224)\n",
    "\n",
    "    return orig_img, img\n",
    "\n",
    "def image_generator(indices, batch_size):\n",
    "\n",
    "    num_batches = int(len(indices) / batch_size)\n",
    "    \n",
    "    while True:\n",
    "        for batch_i in range(num_batches):\n",
    "            if batch_i == num_batches - 1:\n",
    "                # special case: return as many as possible\n",
    "                start_i = batch_i * batch_size\n",
    "                batch_indices = indices[start_i:]\n",
    "                \n",
    "                X = np.zeros((len(batch_indices), 224, 224, 3))\n",
    "                Y = np.zeros((len(batch_indices), 2)) # Change to one-hot\n",
    "            \n",
    "            else:\n",
    "                start_i = batch_i * batch_size\n",
    "                end_i = start_i + batch_size\n",
    "\n",
    "                batch_indices = indices[start_i:end_i]\n",
    "\n",
    "                X = np.zeros((batch_size, 224, 224, 3))\n",
    "                Y = np.zeros((batch_size, 2)) # Change to one-hot\n",
    "            \n",
    "            for i, index in enumerate(batch_indices):\n",
    "                #img = image.load_img(image_paths[index], target_size=(224, 224))\n",
    "                data = np.load(image_paths[int(index)])\n",
    "                depth_map = data['x'].astype(np.float32)\n",
    "                orig_img, ocean = depth_map_to_image(depth_map)\n",
    "                ocean = resize(ocean, (224, 224), mode='constant')\n",
    "                \n",
    "                X[i, :, :, :] = ocean\n",
    "                # Convert to 1 hot vector\n",
    "                one_hot = np.zeros(2)\n",
    "                sanitation_label = sanitation_labels[int(index)]\n",
    "                if sanitation_label == '0':\n",
    "                    one_hot[0] = 1\n",
    "                elif sanitation_label == '1':\n",
    "                    one_hot[1] = 1\n",
    "                Y[i,:] = one_hot\n",
    "            \n",
    "            # use vgg16 preprocessing\n",
    "            X = preprocess_input(X)\n",
    "            \n",
    "            yield (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def camera_model(camera_num):\n",
    "    print(camera_num)\n",
    "    input_tensor = Input(shape=(224,224,3))\n",
    "    model = applications.VGG16(weights='imagenet', include_top=False, input_tensor = input_tensor)\n",
    "    \n",
    "    # build a classifier model to put on top of the convolutional model\n",
    "    x = model.output\n",
    "    x = Flatten(input_shape=(model.output_shape[1:]))(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    x = Dropout(0.05)(x)\n",
    "    x = Dense(256, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
    "    x = Dense(2, activation='softmax', name='output', kernel_initializer='glorot_uniform')(x)\n",
    "\n",
    "    # add new classifier model on top of convolutional base\n",
    "    new_model = Model(model.input, x)\n",
    "    \n",
    "    for layer in new_model.layers[:19]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    #new_model = load_model('pca_camera_' + camera_num + '.hdf5')\n",
    "    \n",
    "    # RMSprop\n",
    "    #new_model.compile(loss='categorical_crossentropy',\n",
    "    #              optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "    new_model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "\n",
    "    minibatch_size = 64#64\n",
    "\n",
    "    train_indices = np.load('pac_arrays/train_' + camera_num + '.npy')\n",
    "    test_indices = np.load('pac_arrays/test_' + camera_num + '.npy')\n",
    "\n",
    "    image_generator(train_indices, minibatch_size)\n",
    "\n",
    "    epochs = 30\n",
    "    minibatch_size = 64#64\n",
    "\n",
    "    train_steps = math.ceil(len(train_indices) / minibatch_size)\n",
    "    test_steps = math.ceil(len(test_indices) / minibatch_size)\n",
    "    \n",
    "    num0 = 0\n",
    "    num1 = 0\n",
    "    for i in train_indices:\n",
    "        if labels[i] == '0':\n",
    "            num0 += 1\n",
    "        elif labels[i] == '1':\n",
    "            num1 += 1\n",
    "    ratio = int(num0 / num1)\n",
    "    print(ratio)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    #class_weight = {0 : 1.,\n",
    "    #1: ratio}\n",
    "    class_weight = {0 : 1.,\n",
    "    1: 250}\n",
    "\n",
    "    # fine-tune the model\n",
    "    history = new_model.fit_generator(\n",
    "        image_generator(train_indices, minibatch_size),\n",
    "        steps_per_epoch=train_steps,\n",
    "        epochs=epochs,\n",
    "        class_weight = class_weight,\n",
    "        validation_data=image_generator(test_indices, minibatch_size),\n",
    "        nb_val_samples=test_steps)\n",
    "\n",
    "    new_model.save('pca_camera_' + camera_num + '.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02\n",
      "12\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:64: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:64: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_steps=11, class_weight={0: 1.0, 1..., steps_per_epoch=31, validation_data=<generator..., epochs=30)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 65s - loss: 2.4221 - acc: 0.5352 - val_loss: 2.8442 - val_acc: 0.0884\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 42s - loss: 1.8918 - acc: 0.5229 - val_loss: 0.3133 - val_acc: 0.9130\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 42s - loss: 1.6983 - acc: 0.5682 - val_loss: 2.8588 - val_acc: 0.0870\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 43s - loss: 1.6303 - acc: 0.5763 - val_loss: 0.4667 - val_acc: 0.9126\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 42s - loss: 1.5558 - acc: 0.5836 - val_loss: 0.9677 - val_acc: 0.0870\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 43s - loss: 1.5104 - acc: 0.5847 - val_loss: 0.2483 - val_acc: 0.9144\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 43s - loss: 1.4786 - acc: 0.6132 - val_loss: 0.3473 - val_acc: 0.9116\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 42s - loss: 1.3354 - acc: 0.6295 - val_loss: 0.6462 - val_acc: 0.7293\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 42s - loss: 1.3291 - acc: 0.6200 - val_loss: 0.3069 - val_acc: 0.9144\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 42s - loss: 1.3112 - acc: 0.6440 - val_loss: 0.5318 - val_acc: 0.8453\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 43s - loss: 1.3415 - acc: 0.6056 - val_loss: 0.2938 - val_acc: 0.9130\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 42s - loss: 1.2069 - acc: 0.6565 - val_loss: 0.2217 - val_acc: 0.9144\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 43s - loss: 1.3017 - acc: 0.6978 - val_loss: 1.8414 - val_acc: 0.0887\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 42s - loss: 1.1061 - acc: 0.6819 - val_loss: 0.3827 - val_acc: 0.8798\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 43s - loss: 1.2233 - acc: 0.6760 - val_loss: 0.9866 - val_acc: 0.1371\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 43s - loss: 1.0829 - acc: 0.6831 - val_loss: 0.2124 - val_acc: 0.9144\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 43s - loss: 1.2360 - acc: 0.7247 - val_loss: 1.4067 - val_acc: 0.0887\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 43s - loss: 1.1136 - acc: 0.6788 - val_loss: 0.2553 - val_acc: 0.9006\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 43s - loss: 1.1218 - acc: 0.7168 - val_loss: 0.7712 - val_acc: 0.6358\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 43s - loss: 1.0765 - acc: 0.6964 - val_loss: 0.2015 - val_acc: 0.9171\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 43s - loss: 1.0755 - acc: 0.7334 - val_loss: 0.7017 - val_acc: 0.6788\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 43s - loss: 1.0680 - acc: 0.7185 - val_loss: 0.3034 - val_acc: 0.9047\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 43s - loss: 0.9893 - acc: 0.7409 - val_loss: 0.8783 - val_acc: 0.5659\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 43s - loss: 1.0213 - acc: 0.7454 - val_loss: 0.3304 - val_acc: 0.8826\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 43s - loss: 1.0208 - acc: 0.7556 - val_loss: 0.4181 - val_acc: 0.8535\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 43s - loss: 0.9738 - acc: 0.7682 - val_loss: 0.1979 - val_acc: 0.9102\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 43s - loss: 0.9437 - acc: 0.7596 - val_loss: 2.1111 - val_acc: 0.0887\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 43s - loss: 1.0573 - acc: 0.7405 - val_loss: 0.2319 - val_acc: 0.9144\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 43s - loss: 0.9561 - acc: 0.7717 - val_loss: 0.3862 - val_acc: 0.8642\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 43s - loss: 0.9781 - acc: 0.7549 - val_loss: 0.9447 - val_acc: 0.5718\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#camera_model('02')\n",
    "camera_nums = np.load('sub_dirs.npy')\n",
    "camera_model(camera_nums[0])\n",
    "#for camera_num in camera_nums:\n",
    "#    camera_model(camera_num)\n",
    "sound_file = 'http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav'\n",
    "display(Audio(url=sound_file, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04\n",
      "9\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:64: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:64: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_steps=11, class_weight={0: 1.0, 1..., steps_per_epoch=31, validation_data=<generator..., epochs=30)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 45s - loss: 2.0348 - acc: 0.5362 - val_loss: 0.4193 - val_acc: 0.9088\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 43s - loss: 1.7285 - acc: 0.5333 - val_loss: 0.3226 - val_acc: 0.9088\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 43s - loss: 1.5339 - acc: 0.5789 - val_loss: 0.7164 - val_acc: 0.1285\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 42s - loss: 1.4326 - acc: 0.5638 - val_loss: 0.2839 - val_acc: 0.9102\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 43s - loss: 1.4264 - acc: 0.5905 - val_loss: 0.7731 - val_acc: 0.0884\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 42s - loss: 1.3414 - acc: 0.5998 - val_loss: 0.6584 - val_acc: 0.7514\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 43s - loss: 1.2679 - acc: 0.6335 - val_loss: 0.3840 - val_acc: 0.9337\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 43s - loss: 1.2447 - acc: 0.6501 - val_loss: 0.5482 - val_acc: 0.9422\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 43s - loss: 1.1840 - acc: 0.6717 - val_loss: 1.4971 - val_acc: 0.0912\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 43s - loss: 1.1779 - acc: 0.6296 - val_loss: 0.2457 - val_acc: 0.9171\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 42s - loss: 1.1349 - acc: 0.6607 - val_loss: 0.2326 - val_acc: 0.9268\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 43s - loss: 1.0760 - acc: 0.7065 - val_loss: 0.2605 - val_acc: 0.9323\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 42s - loss: 1.1274 - acc: 0.7040 - val_loss: 0.8220 - val_acc: 0.0953\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 42s - loss: 1.0475 - acc: 0.6808 - val_loss: 0.2522 - val_acc: 0.9323\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 43s - loss: 1.0659 - acc: 0.6942 - val_loss: 1.2193 - val_acc: 0.0953\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 43s - loss: 1.0616 - acc: 0.6813 - val_loss: 0.2238 - val_acc: 0.9254\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 42s - loss: 1.0236 - acc: 0.7246 - val_loss: 1.0171 - val_acc: 0.0925\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 42s - loss: 1.0041 - acc: 0.7040 - val_loss: 0.2302 - val_acc: 0.9323\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 43s - loss: 1.0517 - acc: 0.7171 - val_loss: 1.3156 - val_acc: 0.0912\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 43s - loss: 1.0012 - acc: 0.6959 - val_loss: 0.2654 - val_acc: 0.9309\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 43s - loss: 0.9568 - acc: 0.7302 - val_loss: 0.2103 - val_acc: 0.9309\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 44s - loss: 1.0006 - acc: 0.7231 - val_loss: 0.5179 - val_acc: 0.8911\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 42s - loss: 0.9448 - acc: 0.7337 - val_loss: 0.5529 - val_acc: 0.8564\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 43s - loss: 0.9729 - acc: 0.7364 - val_loss: 0.3378 - val_acc: 0.9351\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 42s - loss: 0.9632 - acc: 0.7418 - val_loss: 0.2140 - val_acc: 0.9337\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 43s - loss: 0.9131 - acc: 0.7589 - val_loss: 0.2453 - val_acc: 0.9392\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 43s - loss: 0.9016 - acc: 0.7885 - val_loss: 1.0993 - val_acc: 0.0912\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 43s - loss: 0.9103 - acc: 0.7458 - val_loss: 0.2193 - val_acc: 0.9351\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 43s - loss: 0.9271 - acc: 0.7456 - val_loss: 1.4955 - val_acc: 0.0912\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 43s - loss: 0.9043 - acc: 0.7621 - val_loss: 0.2794 - val_acc: 0.9420\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#camera_model('02')\n",
    "camera_nums = np.load('sub_dirs.npy')\n",
    "camera_model(camera_nums[1])\n",
    "#for camera_num in camera_nums:\n",
    "#    camera_model(camera_num)\n",
    "sound_file = 'http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav'\n",
    "display(Audio(url=sound_file, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06\n",
      "1\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:64: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:64: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_steps=11, class_weight={0: 1.0, 1..., steps_per_epoch=31, validation_data=<generator..., epochs=30)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 45s - loss: 1.0284 - acc: 0.5427 - val_loss: 0.7431 - val_acc: 0.6174\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 43s - loss: 0.8100 - acc: 0.5533 - val_loss: 0.7831 - val_acc: 0.3895\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 43s - loss: 0.7894 - acc: 0.5618 - val_loss: 0.7897 - val_acc: 0.6116\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 43s - loss: 0.7913 - acc: 0.5555 - val_loss: 0.6682 - val_acc: 0.5193\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 43s - loss: 0.7486 - acc: 0.5784 - val_loss: 0.6573 - val_acc: 0.6116\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 42s - loss: 0.7319 - acc: 0.5754 - val_loss: 0.6108 - val_acc: 0.7320\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 42s - loss: 0.7327 - acc: 0.5946 - val_loss: 0.7384 - val_acc: 0.6146\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 42s - loss: 0.7048 - acc: 0.6046 - val_loss: 0.6018 - val_acc: 0.7887\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 43s - loss: 0.7084 - acc: 0.6097 - val_loss: 0.5987 - val_acc: 0.7845\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 43s - loss: 0.7019 - acc: 0.6147 - val_loss: 0.7028 - val_acc: 0.6174\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 42s - loss: 0.6915 - acc: 0.6036 - val_loss: 0.5801 - val_acc: 0.7970\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 43s - loss: 0.6845 - acc: 0.6132 - val_loss: 0.8338 - val_acc: 0.6146\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 43s - loss: 0.6703 - acc: 0.6238 - val_loss: 0.5669 - val_acc: 0.7666\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 43s - loss: 0.6633 - acc: 0.6338 - val_loss: 0.6388 - val_acc: 0.6215\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 43s - loss: 0.6570 - acc: 0.6422 - val_loss: 0.6260 - val_acc: 0.6657\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 42s - loss: 0.6472 - acc: 0.6348 - val_loss: 0.6688 - val_acc: 0.6215\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 43s - loss: 0.6424 - acc: 0.6407 - val_loss: 0.5665 - val_acc: 0.7983\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 43s - loss: 0.6379 - acc: 0.6568 - val_loss: 0.5640 - val_acc: 0.6257\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 43s - loss: 0.6353 - acc: 0.6512 - val_loss: 0.5883 - val_acc: 0.8052\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 43s - loss: 0.6249 - acc: 0.6512 - val_loss: 0.5869 - val_acc: 0.6215\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 43s - loss: 0.6212 - acc: 0.6626 - val_loss: 0.5997 - val_acc: 0.6271\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 43s - loss: 0.6189 - acc: 0.6696 - val_loss: 0.6569 - val_acc: 0.4530\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 43s - loss: 0.6233 - acc: 0.6591 - val_loss: 0.7001 - val_acc: 0.6243\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 43s - loss: 0.6177 - acc: 0.6654 - val_loss: 0.6852 - val_acc: 0.4337\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 43s - loss: 0.6144 - acc: 0.6621 - val_loss: 0.6442 - val_acc: 0.6257\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 43s - loss: 0.6073 - acc: 0.6714 - val_loss: 0.5623 - val_acc: 0.8163\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 43s - loss: 0.5984 - acc: 0.6888 - val_loss: 0.5803 - val_acc: 0.6298\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 43s - loss: 0.5961 - acc: 0.6832 - val_loss: 0.5123 - val_acc: 0.7942\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 43s - loss: 0.5920 - acc: 0.6908 - val_loss: 0.5868 - val_acc: 0.6223\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 44s - loss: 0.5956 - acc: 0.6848 - val_loss: 0.5529 - val_acc: 0.8094\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#camera_model('02')\n",
    "camera_nums = np.load('sub_dirs.npy')\n",
    "camera_model(camera_nums[2])\n",
    "#for camera_num in camera_nums:\n",
    "#    camera_model(camera_num)\n",
    "sound_file = 'http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav'\n",
    "display(Audio(url=sound_file, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08\n",
      "8\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:64: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:64: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_steps=11, class_weight={0: 1.0, 1..., steps_per_epoch=31, validation_data=<generator..., epochs=30)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 45s - loss: 2.0149 - acc: 0.5351 - val_loss: 1.0330 - val_acc: 0.0981\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 43s - loss: 1.3884 - acc: 0.5917 - val_loss: 0.4278 - val_acc: 0.9213\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 42s - loss: 1.2971 - acc: 0.6531 - val_loss: 0.3744 - val_acc: 0.9268\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 42s - loss: 1.1677 - acc: 0.6914 - val_loss: 0.4381 - val_acc: 0.9337\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 42s - loss: 1.1400 - acc: 0.6861 - val_loss: 0.3117 - val_acc: 0.9378\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 43s - loss: 1.0460 - acc: 0.7241 - val_loss: 0.4141 - val_acc: 0.9116\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 42s - loss: 1.0834 - acc: 0.7319 - val_loss: 0.2007 - val_acc: 0.9213\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 43s - loss: 0.9343 - acc: 0.7548 - val_loss: 0.3878 - val_acc: 0.9116\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 43s - loss: 0.9023 - acc: 0.7833 - val_loss: 0.2033 - val_acc: 0.9420\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 42s - loss: 0.8787 - acc: 0.7807 - val_loss: 0.1937 - val_acc: 0.9420\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 42s - loss: 0.8876 - acc: 0.7990 - val_loss: 0.1745 - val_acc: 0.9309\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 42s - loss: 0.8851 - acc: 0.7980 - val_loss: 0.2046 - val_acc: 0.9075\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 42s - loss: 0.9029 - acc: 0.8168 - val_loss: 1.9128 - val_acc: 0.1036\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 42s - loss: 0.8605 - acc: 0.7863 - val_loss: 0.1582 - val_acc: 0.9406\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 42s - loss: 0.8062 - acc: 0.8135 - val_loss: 0.2811 - val_acc: 0.9213\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 43s - loss: 0.7994 - acc: 0.8242 - val_loss: 0.2573 - val_acc: 0.9240\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 43s - loss: 0.7704 - acc: 0.8349 - val_loss: 0.3975 - val_acc: 0.8867\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 43s - loss: 0.7857 - acc: 0.8373 - val_loss: 0.3690 - val_acc: 0.8992\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 42s - loss: 0.7686 - acc: 0.8327 - val_loss: 0.2113 - val_acc: 0.9434\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 43s - loss: 0.7192 - acc: 0.8423 - val_loss: 0.1596 - val_acc: 0.9461\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 43s - loss: 0.7280 - acc: 0.8365 - val_loss: 0.4987 - val_acc: 0.8737\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 42s - loss: 0.7218 - acc: 0.8320 - val_loss: 0.1479 - val_acc: 0.9378\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 43s - loss: 0.7149 - acc: 0.8390 - val_loss: 0.2543 - val_acc: 0.9220\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 42s - loss: 0.7153 - acc: 0.8413 - val_loss: 0.3009 - val_acc: 0.9102\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 43s - loss: 0.6977 - acc: 0.8531 - val_loss: 0.3287 - val_acc: 0.9032\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 42s - loss: 0.6751 - acc: 0.8455 - val_loss: 0.2049 - val_acc: 0.9434\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 43s - loss: 0.6925 - acc: 0.8473 - val_loss: 0.1958 - val_acc: 0.9420\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 42s - loss: 0.6710 - acc: 0.8525 - val_loss: 3.2388 - val_acc: 0.1064\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 42s - loss: 0.6873 - acc: 0.8458 - val_loss: 0.1445 - val_acc: 0.9392\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 43s - loss: 0.6849 - acc: 0.8541 - val_loss: 0.2451 - val_acc: 0.9254\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#camera_model('02')\n",
    "camera_nums = np.load('sub_dirs.npy')\n",
    "camera_model(camera_nums[3])\n",
    "#for camera_num in camera_nums:\n",
    "#    camera_model(camera_num)\n",
    "sound_file = 'http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav'\n",
    "display(Audio(url=sound_file, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "19\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:64: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:64: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_steps=11, class_weight={0: 1.0, 1..., steps_per_epoch=31, validation_data=<generator..., epochs=30)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 45s - loss: 2.5912 - acc: 0.5451 - val_loss: 1.0387 - val_acc: 0.0401\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 43s - loss: 1.9647 - acc: 0.5471 - val_loss: 0.7385 - val_acc: 0.2721\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 43s - loss: 1.7842 - acc: 0.5736 - val_loss: 0.1624 - val_acc: 0.9597\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 43s - loss: 1.8207 - acc: 0.6257 - val_loss: 1.4775 - val_acc: 0.0345\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 43s - loss: 1.6993 - acc: 0.5862 - val_loss: 0.1966 - val_acc: 0.9583\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 43s - loss: 1.6044 - acc: 0.6602 - val_loss: 2.2410 - val_acc: 0.0345\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 44s - loss: 1.5768 - acc: 0.6413 - val_loss: 0.3686 - val_acc: 0.9220\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 43s - loss: 1.3859 - acc: 0.6992 - val_loss: 0.7019 - val_acc: 0.6105\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 43s - loss: 1.4304 - acc: 0.6609 - val_loss: 0.2625 - val_acc: 0.9365\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 42s - loss: 1.2874 - acc: 0.7355 - val_loss: 0.2533 - val_acc: 0.9392\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 43s - loss: 1.3330 - acc: 0.7207 - val_loss: 0.9100 - val_acc: 0.2796\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 42s - loss: 1.3041 - acc: 0.7116 - val_loss: 0.4265 - val_acc: 0.8881\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 43s - loss: 1.2793 - acc: 0.7295 - val_loss: 0.4628 - val_acc: 0.8826\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 43s - loss: 1.2399 - acc: 0.7333 - val_loss: 0.9871 - val_acc: 0.2459\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 43s - loss: 1.1706 - acc: 0.7147 - val_loss: 0.4628 - val_acc: 0.8826\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 43s - loss: 1.1760 - acc: 0.7514 - val_loss: 0.1178 - val_acc: 0.9599\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 43s - loss: 1.2108 - acc: 0.7604 - val_loss: 3.7051 - val_acc: 0.0401\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 43s - loss: 1.2577 - acc: 0.7056 - val_loss: 0.3403 - val_acc: 0.8964\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 43s - loss: 1.0582 - acc: 0.7436 - val_loss: 0.2629 - val_acc: 0.9116\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 43s - loss: 1.0371 - acc: 0.7564 - val_loss: 0.5256 - val_acc: 0.8605\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 43s - loss: 1.0755 - acc: 0.7497 - val_loss: 0.1484 - val_acc: 0.9503\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 43s - loss: 1.0714 - acc: 0.7574 - val_loss: 3.5943 - val_acc: 0.0401\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 43s - loss: 1.0901 - acc: 0.7308 - val_loss: 0.2526 - val_acc: 0.9116\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 42s - loss: 1.0125 - acc: 0.7675 - val_loss: 0.3071 - val_acc: 0.8936\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 42s - loss: 0.9979 - acc: 0.7685 - val_loss: 0.2067 - val_acc: 0.9185\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 43s - loss: 1.0070 - acc: 0.7607 - val_loss: 0.1819 - val_acc: 0.9309\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 43s - loss: 1.0024 - acc: 0.7740 - val_loss: 1.1974 - val_acc: 0.2486\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 43s - loss: 0.9428 - acc: 0.7698 - val_loss: 0.1660 - val_acc: 0.9378\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 43s - loss: 0.9302 - acc: 0.7808 - val_loss: 0.2213 - val_acc: 0.9144\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 44s - loss: 0.9750 - acc: 0.7641 - val_loss: 1.9731 - val_acc: 0.0635\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#camera_model('02')\n",
    "camera_nums = np.load('sub_dirs.npy')\n",
    "camera_model(camera_nums[4])\n",
    "#for camera_num in camera_nums:\n",
    "#    camera_model(camera_num)\n",
    "sound_file = 'http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav'\n",
    "display(Audio(url=sound_file, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "494\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:66: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:66: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., steps_per_epoch=31, validation_steps=11, epochs=30, class_weight={0: 1.0, 1...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 43s - loss: 3.6586 - acc: 0.7645 - val_loss: 0.1369 - val_acc: 0.9931\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 40s - loss: 2.6284 - acc: 0.6416 - val_loss: 0.1200 - val_acc: 0.9945\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 41s - loss: 2.7049 - acc: 0.6803 - val_loss: 1.9194 - val_acc: 0.0041\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 41s - loss: 2.5895 - acc: 0.6668 - val_loss: 1.2722 - val_acc: 0.0055\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 41s - loss: 2.6777 - acc: 0.6236 - val_loss: 1.0605 - val_acc: 0.0166\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 41s - loss: 2.3163 - acc: 0.6348 - val_loss: 0.4360 - val_acc: 0.9959\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 41s - loss: 2.7267 - acc: 0.6420 - val_loss: 0.2249 - val_acc: 0.9959\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 41s - loss: 2.8853 - acc: 0.6484 - val_loss: 0.1319 - val_acc: 0.9931\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 41s - loss: 2.4374 - acc: 0.6854 - val_loss: 0.0845 - val_acc: 0.9959\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 41s - loss: 2.8656 - acc: 0.6365 - val_loss: 0.1024 - val_acc: 0.9931\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 40s - loss: 2.7630 - acc: 0.6640 - val_loss: 0.0756 - val_acc: 0.9959\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 41s - loss: 2.3383 - acc: 0.6690 - val_loss: 0.0558 - val_acc: 0.9960\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 41s - loss: 2.9263 - acc: 0.6761 - val_loss: 5.3548 - val_acc: 0.0055\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 41s - loss: 2.9614 - acc: 0.6229 - val_loss: 2.2860 - val_acc: 0.0081\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 40s - loss: 2.6236 - acc: 0.6194 - val_loss: 0.8173 - val_acc: 0.1934\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 41s - loss: 2.0038 - acc: 0.6898 - val_loss: 0.1177 - val_acc: 0.9959\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 41s - loss: 2.8472 - acc: 0.6333 - val_loss: 0.1465 - val_acc: 0.9959\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 41s - loss: 2.3330 - acc: 0.6624 - val_loss: 0.1016 - val_acc: 0.9959\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 41s - loss: 2.2310 - acc: 0.6909 - val_loss: 0.0807 - val_acc: 0.9959\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 41s - loss: 3.0105 - acc: 0.6433 - val_loss: 0.0695 - val_acc: 0.9959\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 41s - loss: 2.4384 - acc: 0.6607 - val_loss: 0.0683 - val_acc: 0.9931\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 40s - loss: 2.4999 - acc: 0.6640 - val_loss: 0.0531 - val_acc: 0.9959\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 41s - loss: 2.6174 - acc: 0.6855 - val_loss: 6.8506 - val_acc: 0.0040\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 41s - loss: 2.2509 - acc: 0.6551 - val_loss: 5.0179 - val_acc: 0.0069\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 41s - loss: 3.0300 - acc: 0.6386 - val_loss: 4.1967 - val_acc: 0.0067\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 41s - loss: 2.4409 - acc: 0.6359 - val_loss: 2.7113 - val_acc: 0.0249\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 42s - loss: 2.7243 - acc: 0.6167 - val_loss: 1.2626 - val_acc: 0.1035\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 41s - loss: 2.1372 - acc: 0.6528 - val_loss: 0.4210 - val_acc: 0.9254\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 41s - loss: 2.2220 - acc: 0.6932 - val_loss: 0.1132 - val_acc: 0.9960\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 42s - loss: 2.6962 - acc: 0.6419 - val_loss: 0.1982 - val_acc: 0.9945\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#camera_model('02')\n",
    "camera_nums = np.load('sub_dirs.npy')\n",
    "camera_model(camera_nums[5])\n",
    "#for camera_num in camera_nums:\n",
    "#    camera_model(camera_num)\n",
    "sound_file = 'http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav'\n",
    "display(Audio(url=sound_file, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "3\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:64: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:64: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_steps=11, class_weight={0: 1.0, 1..., steps_per_epoch=31, validation_data=<generator..., epochs=30)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 45s - loss: 1.7795 - acc: 0.5201 - val_loss: 1.4953 - val_acc: 0.2251\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 43s - loss: 1.2657 - acc: 0.5327 - val_loss: 0.4521 - val_acc: 0.7693\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 43s - loss: 1.1587 - acc: 0.5768 - val_loss: 0.9264 - val_acc: 0.2251\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 43s - loss: 1.0286 - acc: 0.6103 - val_loss: 0.4176 - val_acc: 0.7997\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 43s - loss: 0.9671 - acc: 0.6515 - val_loss: 0.9340 - val_acc: 0.4558\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 43s - loss: 0.9023 - acc: 0.6615 - val_loss: 0.3717 - val_acc: 0.7804\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 42s - loss: 0.8767 - acc: 0.6902 - val_loss: 0.7554 - val_acc: 0.7196\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 43s - loss: 0.8369 - acc: 0.7092 - val_loss: 0.3545 - val_acc: 0.7873\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 43s - loss: 0.8253 - acc: 0.7157 - val_loss: 1.1515 - val_acc: 0.4583\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 43s - loss: 0.7874 - acc: 0.7308 - val_loss: 0.3382 - val_acc: 0.8066\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 43s - loss: 0.7727 - acc: 0.7466 - val_loss: 0.6630 - val_acc: 0.7362\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 42s - loss: 0.7397 - acc: 0.7605 - val_loss: 0.3288 - val_acc: 0.8122\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 43s - loss: 0.7604 - acc: 0.7487 - val_loss: 0.7931 - val_acc: 0.7210\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 43s - loss: 0.7331 - acc: 0.7575 - val_loss: 0.3953 - val_acc: 0.7680\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 42s - loss: 0.6966 - acc: 0.7726 - val_loss: 0.3717 - val_acc: 0.7887\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 43s - loss: 0.7068 - acc: 0.7681 - val_loss: 0.4503 - val_acc: 0.7583\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 42s - loss: 0.6916 - acc: 0.7583 - val_loss: 0.3970 - val_acc: 0.7693\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 43s - loss: 0.6725 - acc: 0.7727 - val_loss: 0.3140 - val_acc: 0.8329\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 43s - loss: 0.6975 - acc: 0.7757 - val_loss: 1.0193 - val_acc: 0.6768\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 43s - loss: 0.6876 - acc: 0.7666 - val_loss: 0.3203 - val_acc: 0.8149\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 43s - loss: 0.6672 - acc: 0.7777 - val_loss: 0.5766 - val_acc: 0.7569\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 43s - loss: 0.6714 - acc: 0.7724 - val_loss: 0.3633 - val_acc: 0.7956\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 43s - loss: 0.6579 - acc: 0.7747 - val_loss: 0.7312 - val_acc: 0.7376\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 43s - loss: 0.6539 - acc: 0.7858 - val_loss: 0.3766 - val_acc: 0.7901\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 43s - loss: 0.6363 - acc: 0.7850 - val_loss: 0.3171 - val_acc: 0.8218\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 42s - loss: 0.6491 - acc: 0.7832 - val_loss: 0.8197 - val_acc: 0.7348\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 43s - loss: 0.6488 - acc: 0.7802 - val_loss: 0.4585 - val_acc: 0.7634\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 43s - loss: 0.6311 - acc: 0.7825 - val_loss: 0.4121 - val_acc: 0.7680\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 43s - loss: 0.6224 - acc: 0.7898 - val_loss: 0.5650 - val_acc: 0.7554\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 44s - loss: 0.6277 - acc: 0.7807 - val_loss: 0.3285 - val_acc: 0.8177\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#camera_model('02')\n",
    "camera_nums = np.load('sub_dirs.npy')\n",
    "camera_model(camera_nums[6])\n",
    "#for camera_num in camera_nums:\n",
    "#    camera_model(camera_num)\n",
    "sound_file = 'http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav'\n",
    "display(Audio(url=sound_file, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "151\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:64: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:64: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_steps=11, class_weight={0: 1.0, 1..., steps_per_epoch=31, validation_data=<generator..., epochs=30)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 45s - loss: 3.6487 - acc: 0.5537 - val_loss: 0.3132 - val_acc: 0.9917\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 43s - loss: 2.5739 - acc: 0.5764 - val_loss: 3.0696 - val_acc: 0.0097\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 43s - loss: 2.5260 - acc: 0.5839 - val_loss: 1.7603 - val_acc: 0.0081\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 43s - loss: 2.3125 - acc: 0.5918 - val_loss: 0.4752 - val_acc: 0.9903\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 43s - loss: 2.4455 - acc: 0.5779 - val_loss: 0.1968 - val_acc: 0.9919\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 43s - loss: 2.3086 - acc: 0.6048 - val_loss: 0.1085 - val_acc: 0.9903\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 43s - loss: 2.1754 - acc: 0.6328 - val_loss: 0.0870 - val_acc: 0.9903\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 43s - loss: 2.7933 - acc: 0.6348 - val_loss: 4.1997 - val_acc: 0.0097\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 43s - loss: 2.4605 - acc: 0.6036 - val_loss: 1.0950 - val_acc: 0.1174\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 43s - loss: 2.4593 - acc: 0.6101 - val_loss: 2.0812 - val_acc: 0.0124\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 42s - loss: 2.5093 - acc: 0.6169 - val_loss: 0.2392 - val_acc: 0.9917\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 43s - loss: 2.2414 - acc: 0.6229 - val_loss: 0.1581 - val_acc: 0.9917\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 43s - loss: 2.3356 - acc: 0.6484 - val_loss: 3.3221 - val_acc: 0.0097\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 43s - loss: 2.2212 - acc: 0.6522 - val_loss: 1.6434 - val_acc: 0.0887\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 43s - loss: 2.1681 - acc: 0.6185 - val_loss: 0.2727 - val_acc: 0.9903\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 43s - loss: 2.1287 - acc: 0.6564 - val_loss: 0.1241 - val_acc: 0.9919\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 42s - loss: 1.8930 - acc: 0.6685 - val_loss: 0.0858 - val_acc: 0.9903\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 42s - loss: 1.9404 - acc: 0.6604 - val_loss: 0.0619 - val_acc: 0.9903\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 43s - loss: 2.0805 - acc: 0.6842 - val_loss: 0.0622 - val_acc: 0.9903\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 43s - loss: 2.0154 - acc: 0.6827 - val_loss: 0.0557 - val_acc: 0.9903\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 43s - loss: 1.8574 - acc: 0.7040 - val_loss: 0.0516 - val_acc: 0.9903\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 43s - loss: 1.8396 - acc: 0.6906 - val_loss: 0.0480 - val_acc: 0.9917\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 43s - loss: 2.2460 - acc: 0.6487 - val_loss: 0.0461 - val_acc: 0.9917\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 43s - loss: 2.3218 - acc: 0.6676 - val_loss: 7.3073 - val_acc: 0.0083\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 42s - loss: 1.9987 - acc: 0.6505 - val_loss: 4.4705 - val_acc: 0.0097\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 43s - loss: 2.1497 - acc: 0.6130 - val_loss: 2.3761 - val_acc: 0.0898\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 44s - loss: 1.9503 - acc: 0.6822 - val_loss: 0.9178 - val_acc: 0.2755\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 43s - loss: 2.0351 - acc: 0.6343 - val_loss: 0.2513 - val_acc: 0.9738\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 43s - loss: 1.9881 - acc: 0.6785 - val_loss: 0.7208 - val_acc: 0.3831\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 44s - loss: 2.1024 - acc: 0.6581 - val_loss: 0.8412 - val_acc: 0.3163\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#camera_model('02')\n",
    "camera_nums = np.load('sub_dirs.npy')\n",
    "camera_model(camera_nums[7])\n",
    "#for camera_num in camera_nums:\n",
    "#    camera_model(camera_num)\n",
    "sound_file = 'http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav'\n",
    "display(Audio(url=sound_file, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "5\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:64: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:64: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_steps=11, class_weight={0: 1.0, 1..., steps_per_epoch=31, validation_data=<generator..., epochs=30)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 45s - loss: 1.8639 - acc: 0.5612 - val_loss: 1.9856 - val_acc: 0.1395\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 43s - loss: 1.4106 - acc: 0.5646 - val_loss: 0.3803 - val_acc: 0.8633\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 44s - loss: 1.3407 - acc: 0.5889 - val_loss: 0.4605 - val_acc: 0.8589\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 43s - loss: 1.3630 - acc: 0.6014 - val_loss: 0.4167 - val_acc: 0.8633\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 43s - loss: 1.3437 - acc: 0.6281 - val_loss: 3.1174 - val_acc: 0.1411\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 43s - loss: 1.3281 - acc: 0.5709 - val_loss: 0.3944 - val_acc: 0.8605\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 43s - loss: 1.2424 - acc: 0.6221 - val_loss: 1.4143 - val_acc: 0.1411\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 43s - loss: 1.2409 - acc: 0.6100 - val_loss: 0.4464 - val_acc: 0.8564\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 43s - loss: 1.1803 - acc: 0.6466 - val_loss: 0.6909 - val_acc: 0.6371\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 43s - loss: 1.1628 - acc: 0.6500 - val_loss: 0.3779 - val_acc: 0.8522\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 43s - loss: 1.1070 - acc: 0.6665 - val_loss: 1.0849 - val_acc: 0.1478\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 42s - loss: 1.0582 - acc: 0.6630 - val_loss: 0.3564 - val_acc: 0.8564\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 43s - loss: 1.1532 - acc: 0.6560 - val_loss: 0.4448 - val_acc: 0.8564\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 43s - loss: 1.1092 - acc: 0.6415 - val_loss: 0.4788 - val_acc: 0.8481\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 43s - loss: 1.0967 - acc: 0.6603 - val_loss: 0.9872 - val_acc: 0.2293\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 42s - loss: 1.1118 - acc: 0.6372 - val_loss: 0.3481 - val_acc: 0.8577\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 42s - loss: 1.0879 - acc: 0.6731 - val_loss: 0.4578 - val_acc: 0.8564\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 43s - loss: 1.0622 - acc: 0.6604 - val_loss: 0.6722 - val_acc: 0.7044\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 43s - loss: 0.9985 - acc: 0.6968 - val_loss: 0.3752 - val_acc: 0.8577\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 43s - loss: 1.0092 - acc: 0.7057 - val_loss: 0.7461 - val_acc: 0.5180\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 43s - loss: 0.9920 - acc: 0.6827 - val_loss: 0.3518 - val_acc: 0.8564\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 43s - loss: 0.9463 - acc: 0.7377 - val_loss: 0.3525 - val_acc: 0.8522\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 42s - loss: 1.0127 - acc: 0.6903 - val_loss: 0.7433 - val_acc: 0.5939\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 43s - loss: 0.9947 - acc: 0.6971 - val_loss: 0.4002 - val_acc: 0.8577\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 43s - loss: 0.9924 - acc: 0.7076 - val_loss: 0.5950 - val_acc: 0.7944\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 43s - loss: 0.9548 - acc: 0.7200 - val_loss: 0.3635 - val_acc: 0.8577\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 43s - loss: 0.9946 - acc: 0.6841 - val_loss: 0.3314 - val_acc: 0.8575\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 43s - loss: 0.9422 - acc: 0.7195 - val_loss: 0.3250 - val_acc: 0.8564\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 43s - loss: 1.0146 - acc: 0.6893 - val_loss: 0.8092 - val_acc: 0.4247\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 44s - loss: 0.9332 - acc: 0.6959 - val_loss: 0.3222 - val_acc: 0.8564\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#camera_model('02')\n",
    "camera_nums = np.load('sub_dirs.npy')\n",
    "camera_model(camera_nums[8])\n",
    "#for camera_num in camera_nums:\n",
    "#    camera_model(camera_num)\n",
    "sound_file = 'http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav'\n",
    "display(Audio(url=sound_file, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "72\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:64: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:64: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_steps=11, class_weight={0: 1.0, 1..., steps_per_epoch=31, validation_data=<generator..., epochs=30)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 45s - loss: 2.8082 - acc: 0.5680 - val_loss: 0.1901 - val_acc: 0.9834\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 42s - loss: 2.3604 - acc: 0.5026 - val_loss: 1.6015 - val_acc: 0.0152\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 43s - loss: 2.1211 - acc: 0.4965 - val_loss: 0.2487 - val_acc: 0.9848\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 43s - loss: 2.0441 - acc: 0.5472 - val_loss: 0.1357 - val_acc: 0.9862\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 43s - loss: 2.0425 - acc: 0.5613 - val_loss: 0.1004 - val_acc: 0.9848\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 43s - loss: 1.9689 - acc: 0.5435 - val_loss: 1.7726 - val_acc: 0.0180\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 43s - loss: 2.1238 - acc: 0.5363 - val_loss: 0.1614 - val_acc: 0.9848\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 43s - loss: 1.7098 - acc: 0.5791 - val_loss: 0.1014 - val_acc: 0.9820\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 43s - loss: 2.1100 - acc: 0.5771 - val_loss: 3.7619 - val_acc: 0.0152\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 43s - loss: 1.9919 - acc: 0.5378 - val_loss: 1.4721 - val_acc: 0.0152\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 43s - loss: 1.9608 - acc: 0.5308 - val_loss: 0.5488 - val_acc: 0.7901\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 43s - loss: 1.8085 - acc: 0.6179 - val_loss: 0.1738 - val_acc: 0.9848\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 42s - loss: 1.8038 - acc: 0.6050 - val_loss: 1.6431 - val_acc: 0.0138\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 42s - loss: 1.7568 - acc: 0.5701 - val_loss: 0.1786 - val_acc: 0.9834\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 43s - loss: 1.7690 - acc: 0.5987 - val_loss: 0.5315 - val_acc: 0.7914\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 43s - loss: 1.8371 - acc: 0.5731 - val_loss: 0.3075 - val_acc: 0.9382\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 43s - loss: 1.7093 - acc: 0.6481 - val_loss: 1.0243 - val_acc: 0.1202\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 43s - loss: 1.8954 - acc: 0.5867 - val_loss: 2.0174 - val_acc: 0.0148\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 43s - loss: 1.5530 - acc: 0.6637 - val_loss: 0.2400 - val_acc: 0.9572\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 44s - loss: 1.4341 - acc: 0.6836 - val_loss: 0.9149 - val_acc: 0.4395\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 43s - loss: 1.5495 - acc: 0.6526 - val_loss: 0.1986 - val_acc: 0.9738\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 42s - loss: 1.5002 - acc: 0.6798 - val_loss: 0.0977 - val_acc: 0.9834\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 43s - loss: 1.5172 - acc: 0.6625 - val_loss: 0.0696 - val_acc: 0.9848\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 44s - loss: 1.6772 - acc: 0.7142 - val_loss: 5.1045 - val_acc: 0.0148\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 42s - loss: 1.5674 - acc: 0.6613 - val_loss: 0.9267 - val_acc: 0.5235\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 43s - loss: 1.4555 - acc: 0.6864 - val_loss: 0.4449 - val_acc: 0.8066\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 43s - loss: 1.6958 - acc: 0.6758 - val_loss: 3.4739 - val_acc: 0.0138\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 43s - loss: 1.4690 - acc: 0.6851 - val_loss: 0.3768 - val_acc: 0.8356\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 43s - loss: 1.4303 - acc: 0.7121 - val_loss: 5.7523 - val_acc: 0.0180\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 44s - loss: 1.4927 - acc: 0.6671 - val_loss: 0.2236 - val_acc: 0.9144\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#camera_model('02')\n",
    "camera_nums = np.load('sub_dirs.npy')\n",
    "camera_model(camera_nums[9])\n",
    "#for camera_num in camera_nums:\n",
    "#    camera_model(camera_num)\n",
    "sound_file = 'http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav'\n",
    "display(Audio(url=sound_file, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "3\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:64: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:64: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_steps=11, class_weight={0: 1.0, 1..., steps_per_epoch=31, validation_data=<generator..., epochs=30)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 45s - loss: 1.7040 - acc: 0.5372 - val_loss: 0.8422 - val_acc: 0.2486\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 43s - loss: 1.2467 - acc: 0.5501 - val_loss: 0.5108 - val_acc: 0.7555\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 44s - loss: 1.1353 - acc: 0.5799 - val_loss: 0.5707 - val_acc: 0.7513\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 43s - loss: 1.0905 - acc: 0.6008 - val_loss: 0.6125 - val_acc: 0.8122\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 43s - loss: 1.0649 - acc: 0.6236 - val_loss: 0.4652 - val_acc: 0.7804\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 43s - loss: 1.0154 - acc: 0.6229 - val_loss: 0.5076 - val_acc: 0.8467\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 43s - loss: 0.9928 - acc: 0.6475 - val_loss: 0.6192 - val_acc: 0.7141\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 43s - loss: 0.9648 - acc: 0.6568 - val_loss: 0.4482 - val_acc: 0.7831\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 42s - loss: 0.9693 - acc: 0.6501 - val_loss: 1.3085 - val_acc: 0.2486\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 43s - loss: 0.9282 - acc: 0.6586 - val_loss: 0.4418 - val_acc: 0.7873\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 43s - loss: 0.9351 - acc: 0.6606 - val_loss: 1.0127 - val_acc: 0.2487\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 43s - loss: 0.8857 - acc: 0.7003 - val_loss: 0.4009 - val_acc: 0.8080\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 43s - loss: 0.8922 - acc: 0.6983 - val_loss: 0.6483 - val_acc: 0.6237\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 42s - loss: 0.8710 - acc: 0.6806 - val_loss: 0.3910 - val_acc: 0.8508\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 43s - loss: 0.8538 - acc: 0.6886 - val_loss: 0.6071 - val_acc: 0.7058\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 43s - loss: 0.8422 - acc: 0.7011 - val_loss: 0.4003 - val_acc: 0.8702\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 43s - loss: 0.8468 - acc: 0.7001 - val_loss: 0.5853 - val_acc: 0.7307\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 43s - loss: 0.8184 - acc: 0.7107 - val_loss: 0.3815 - val_acc: 0.8135\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 43s - loss: 0.8277 - acc: 0.7149 - val_loss: 1.0671 - val_acc: 0.2459\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 43s - loss: 0.8177 - acc: 0.7012 - val_loss: 0.3571 - val_acc: 0.8494\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 43s - loss: 0.8120 - acc: 0.7254 - val_loss: 0.8823 - val_acc: 0.2749\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 43s - loss: 0.7587 - acc: 0.7720 - val_loss: 0.4110 - val_acc: 0.8715\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 43s - loss: 0.7783 - acc: 0.7633 - val_loss: 0.8457 - val_acc: 0.2942\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 43s - loss: 0.7928 - acc: 0.7311 - val_loss: 0.3477 - val_acc: 0.8481\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 43s - loss: 0.7651 - acc: 0.7591 - val_loss: 0.9020 - val_acc: 0.2845\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 43s - loss: 0.7574 - acc: 0.7429 - val_loss: 0.3381 - val_acc: 0.8591\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 43s - loss: 0.7507 - acc: 0.7641 - val_loss: 0.6671 - val_acc: 0.6381\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 43s - loss: 0.7312 - acc: 0.7634 - val_loss: 0.3359 - val_acc: 0.8467\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 43s - loss: 0.7437 - acc: 0.7635 - val_loss: 0.4900 - val_acc: 0.8122\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 44s - loss: 0.7197 - acc: 0.7684 - val_loss: 0.3409 - val_acc: 0.8785\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#camera_model('02')\n",
    "camera_nums = np.load('sub_dirs.npy')\n",
    "camera_model(camera_nums[10])\n",
    "#for camera_num in camera_nums:\n",
    "#    camera_model(camera_num)\n",
    "sound_file = 'http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav'\n",
    "display(Audio(url=sound_file, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "2\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:64: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:64: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_steps=11, class_weight={0: 1.0, 1..., steps_per_epoch=31, validation_data=<generator..., epochs=30)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 45s - loss: 1.4941 - acc: 0.5099 - val_loss: 0.6723 - val_acc: 0.7610\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 42s - loss: 1.1921 - acc: 0.5241 - val_loss: 1.2083 - val_acc: 0.3218\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 43s - loss: 1.1224 - acc: 0.5186 - val_loss: 0.8222 - val_acc: 0.6851\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 42s - loss: 1.1128 - acc: 0.5512 - val_loss: 1.1807 - val_acc: 0.3066\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 43s - loss: 1.0750 - acc: 0.5265 - val_loss: 0.7186 - val_acc: 0.6809\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 43s - loss: 1.0648 - acc: 0.5493 - val_loss: 0.5834 - val_acc: 0.7155\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 43s - loss: 1.0288 - acc: 0.5400 - val_loss: 0.6149 - val_acc: 0.7887\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 43s - loss: 1.0033 - acc: 0.5588 - val_loss: 0.7741 - val_acc: 0.3149\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 43s - loss: 0.9957 - acc: 0.5514 - val_loss: 0.6503 - val_acc: 0.6174\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 43s - loss: 1.0000 - acc: 0.5641 - val_loss: 0.5470 - val_acc: 0.7003\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 42s - loss: 0.9615 - acc: 0.5812 - val_loss: 0.5777 - val_acc: 0.7997\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 43s - loss: 0.9660 - acc: 0.5763 - val_loss: 1.1491 - val_acc: 0.3212\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 43s - loss: 0.9839 - acc: 0.5649 - val_loss: 0.5911 - val_acc: 0.6796\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 44s - loss: 0.9332 - acc: 0.5978 - val_loss: 0.7378 - val_acc: 0.3737\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 43s - loss: 0.9342 - acc: 0.5751 - val_loss: 0.6005 - val_acc: 0.6796\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 43s - loss: 0.9129 - acc: 0.6012 - val_loss: 0.6861 - val_acc: 0.4355\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 42s - loss: 0.9009 - acc: 0.5992 - val_loss: 0.5566 - val_acc: 0.6892\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 43s - loss: 0.9148 - acc: 0.6021 - val_loss: 1.0470 - val_acc: 0.3163\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 43s - loss: 0.9047 - acc: 0.6012 - val_loss: 0.5198 - val_acc: 0.7721\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 43s - loss: 0.8883 - acc: 0.6200 - val_loss: 0.5713 - val_acc: 0.8315\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 43s - loss: 0.8813 - acc: 0.6176 - val_loss: 0.5093 - val_acc: 0.7320\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 42s - loss: 0.8615 - acc: 0.6274 - val_loss: 0.6187 - val_acc: 0.6533\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 42s - loss: 0.8668 - acc: 0.6234 - val_loss: 0.5451 - val_acc: 0.7030\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 43s - loss: 0.8629 - acc: 0.6350 - val_loss: 0.7010 - val_acc: 0.4337\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 44s - loss: 0.8507 - acc: 0.6395 - val_loss: 0.5463 - val_acc: 0.6935\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 43s - loss: 0.8365 - acc: 0.6504 - val_loss: 0.5105 - val_acc: 0.8204\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 42s - loss: 0.8369 - acc: 0.6481 - val_loss: 0.9135 - val_acc: 0.3177\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 42s - loss: 0.8412 - acc: 0.6322 - val_loss: 0.5700 - val_acc: 0.7003\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 42s - loss: 0.8306 - acc: 0.6580 - val_loss: 0.5385 - val_acc: 0.8370\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 44s - loss: 0.8161 - acc: 0.6611 - val_loss: 0.5882 - val_acc: 0.7528\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#camera_model('02')\n",
    "camera_nums = np.load('sub_dirs.npy')\n",
    "camera_model(camera_nums[11])\n",
    "#for camera_num in camera_nums:\n",
    "#    camera_model(camera_num)\n",
    "sound_file = 'http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav'\n",
    "display(Audio(url=sound_file, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "2\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:64: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:64: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_steps=11, class_weight={0: 1.0, 1..., steps_per_epoch=31, validation_data=<generator..., epochs=30)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 45s - loss: 1.5817 - acc: 0.5258 - val_loss: 0.5868 - val_acc: 0.7279\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 43s - loss: 1.1974 - acc: 0.5384 - val_loss: 0.7576 - val_acc: 0.2859\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 43s - loss: 1.1488 - acc: 0.5354 - val_loss: 0.5619 - val_acc: 0.7312\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 43s - loss: 1.0918 - acc: 0.5477 - val_loss: 0.9061 - val_acc: 0.2804\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 44s - loss: 1.0707 - acc: 0.5717 - val_loss: 0.5687 - val_acc: 0.7379\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 43s - loss: 1.0531 - acc: 0.5817 - val_loss: 0.8535 - val_acc: 0.2859\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 43s - loss: 1.0105 - acc: 0.5599 - val_loss: 0.6625 - val_acc: 0.7312\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 43s - loss: 1.0292 - acc: 0.5869 - val_loss: 1.2430 - val_acc: 0.2804\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 44s - loss: 1.0241 - acc: 0.5666 - val_loss: 0.5519 - val_acc: 0.7325\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 43s - loss: 0.9912 - acc: 0.5800 - val_loss: 0.6695 - val_acc: 0.5262\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 42s - loss: 0.9719 - acc: 0.5963 - val_loss: 0.5974 - val_acc: 0.7459\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 43s - loss: 0.9382 - acc: 0.6123 - val_loss: 0.5675 - val_acc: 0.7224\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 43s - loss: 0.9339 - acc: 0.6194 - val_loss: 0.5426 - val_acc: 0.7406\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 43s - loss: 0.9546 - acc: 0.6135 - val_loss: 1.4895 - val_acc: 0.2804\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 43s - loss: 0.9602 - acc: 0.5944 - val_loss: 0.5499 - val_acc: 0.7325\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 42s - loss: 0.9288 - acc: 0.6153 - val_loss: 0.7021 - val_acc: 0.5014\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 43s - loss: 0.9295 - acc: 0.6078 - val_loss: 0.5345 - val_acc: 0.7362\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 42s - loss: 0.9227 - acc: 0.6199 - val_loss: 0.5712 - val_acc: 0.7445\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 42s - loss: 0.9103 - acc: 0.6204 - val_loss: 0.5685 - val_acc: 0.7445\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 43s - loss: 0.9106 - acc: 0.6211 - val_loss: 0.5526 - val_acc: 0.7541\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 42s - loss: 0.9145 - acc: 0.6194 - val_loss: 0.5968 - val_acc: 0.6975\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 43s - loss: 0.8976 - acc: 0.6239 - val_loss: 0.5263 - val_acc: 0.7392\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 43s - loss: 0.8969 - acc: 0.6214 - val_loss: 0.6805 - val_acc: 0.5152\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 43s - loss: 0.8819 - acc: 0.6261 - val_loss: 0.5297 - val_acc: 0.7473\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 42s - loss: 0.8934 - acc: 0.6273 - val_loss: 1.0273 - val_acc: 0.3273\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 43s - loss: 0.8907 - acc: 0.6266 - val_loss: 0.5985 - val_acc: 0.7251\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 43s - loss: 0.8879 - acc: 0.6257 - val_loss: 0.9126 - val_acc: 0.3453\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 43s - loss: 0.8838 - acc: 0.6181 - val_loss: 0.5467 - val_acc: 0.7486\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 43s - loss: 0.8664 - acc: 0.6321 - val_loss: 0.6128 - val_acc: 0.6450\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 44s - loss: 0.8639 - acc: 0.6364 - val_loss: 0.5168 - val_acc: 0.7376\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#camera_model('02')\n",
    "camera_nums = np.load('sub_dirs.npy')\n",
    "camera_model(camera_nums[12])\n",
    "#for camera_num in camera_nums:\n",
    "#    camera_model(camera_num)\n",
    "sound_file = 'http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav'\n",
    "display(Audio(url=sound_file, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_image_generator(indices, batch_size):\n",
    "\n",
    "    num_batches = int(len(indices) / batch_size)\n",
    "    \n",
    "    while True:\n",
    "        for batch_i in range(num_batches):\n",
    "            if batch_i == num_batches - 1:\n",
    "                # special case: return as many as possible\n",
    "                start_i = batch_i * batch_size\n",
    "                batch_indices = indices[start_i:]\n",
    "                \n",
    "                X = np.zeros((len(batch_indices), 224, 224, 3))\n",
    "                Y = np.zeros((len(batch_indices), 2)) # Change to one-hot\n",
    "            \n",
    "            else:\n",
    "                start_i = batch_i * batch_size\n",
    "                end_i = start_i + batch_size\n",
    "\n",
    "                batch_indices = indices[start_i:end_i]\n",
    "\n",
    "                X = np.zeros((batch_size, 224, 224, 3))\n",
    "                Y = np.zeros((batch_size, 2)) # Change to one-hot\n",
    "            \n",
    "            for i, index in enumerate(batch_indices):\n",
    "                #img = image.load_img(image_paths[index], target_size=(224, 224))\n",
    "                data = np.load(image_paths[int(index)])\n",
    "                depth_map = data['x'].astype(np.float32)\n",
    "                orig_img, ocean = depth_map_to_image(depth_map)\n",
    "                ocean = resize(ocean, (224, 224), mode='constant')\n",
    "                \n",
    "                X[i, :, :, :] = ocean\n",
    "                # Convert to 1 hot vector\n",
    "                one_hot = np.zeros(2)\n",
    "                sanitation_label = sanitation_labels[int(index)]\n",
    "                zero_counter = 0\n",
    "                one_counter = 0\n",
    "                if sanitation_label == '0':\n",
    "                    one_hot[0] = 1\n",
    "                    zero_counter+=1\n",
    "                elif sanitation_label == '1':\n",
    "                    one_hot[1] = 1\n",
    "                    one_counter += 1\n",
    "                Y[i,:] = one_hot\n",
    "            \n",
    "            # use vgg16 preprocessing\n",
    "            X = preprocess_input(X)\n",
    "            \n",
    "            ratio = int(zero_counter / one_counter)\n",
    "\n",
    "            #class_weight = {0 : 1.,\n",
    "            #1: ratio}\n",
    "            class_weight = {0 : 1.,\n",
    "            1: ratio}\n",
    "            \n",
    "            yield (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "31/31 [==============================] - 30s - loss: 1.1638 - acc: 0.7455    \n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 11s - loss: 0.9007 - acc: 0.7710    \n"
     ]
    }
   ],
   "source": [
    "camera_num = '02'\n",
    "new_model = load_model('pca_camera_' + camera_num + '.hdf5')\n",
    "    \n",
    "# RMSprop\n",
    "#new_model.compile(loss='categorical_crossentropy',\n",
    "#              optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "new_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "\n",
    "minibatch_size = 64#64\n",
    "\n",
    "train_indices = np.load('pac_arrays/train_' + camera_num + '.npy')\n",
    "test_indices = np.load('pac_arrays/test_' + camera_num + '.npy')\n",
    "\n",
    "#image_generator(train_indices, minibatch_size)\n",
    "\n",
    "epochs = 1\n",
    "minibatch_size = 64#64\n",
    "\n",
    "train_steps = math.ceil(len(train_indices) / minibatch_size)\n",
    "test_steps = math.ceil(len(test_indices) / minibatch_size)\n",
    "\n",
    "num0 = 0\n",
    "num1 = 0\n",
    "for i in train_indices:\n",
    "    if labels[i] == '0':\n",
    "        num0 += 1\n",
    "    elif labels[i] == '1':\n",
    "        num1 += 1\n",
    "train_ratio = int(num0 / num1)\n",
    "\n",
    "num0 = 0\n",
    "num1 = 0\n",
    "for i in test_indices:\n",
    "    if labels[i] == '0':\n",
    "        num0 += 1\n",
    "    elif labels[i] == '1':\n",
    "        num1 += 1\n",
    "test_ratio = int(num0 / num1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#class_weight = {0 : 1.,\n",
    "#1: ratio}\n",
    "train_weight = {0 : 1.,\n",
    "1: train_ratio}\n",
    "\n",
    "test_weight = {0 : 1.,\n",
    "1: test_ratio}\n",
    "\n",
    "# fine-tune the model\n",
    "history = new_model.fit_generator(\n",
    "    image_generator(train_indices, minibatch_size),\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=epochs,\n",
    "    class_weight = train_weight\n",
    "    )\n",
    "\n",
    "history = new_model.fit_generator(\n",
    "    image_generator(test_indices, minibatch_size),\n",
    "    steps_per_epoch=test_steps,\n",
    "    epochs=epochs,\n",
    "    class_weight = test_weight\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "31/31 [==============================] - 30s - loss: 1.1137 - acc: 0.7196    \n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 11s - loss: 0.7966 - acc: 0.7678    \n"
     ]
    }
   ],
   "source": [
    "camera_num = '04'\n",
    "new_model = load_model('pca_camera_' + camera_num + '.hdf5')\n",
    "    \n",
    "# RMSprop\n",
    "#new_model.compile(loss='categorical_crossentropy',\n",
    "#              optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "new_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "\n",
    "minibatch_size = 64#64\n",
    "\n",
    "train_indices = np.load('pac_arrays/train_' + camera_num + '.npy')\n",
    "test_indices = np.load('pac_arrays/test_' + camera_num + '.npy')\n",
    "\n",
    "#image_generator(train_indices, minibatch_size)\n",
    "\n",
    "epochs = 1\n",
    "minibatch_size = 64#64\n",
    "\n",
    "train_steps = math.ceil(len(train_indices) / minibatch_size)\n",
    "test_steps = math.ceil(len(test_indices) / minibatch_size)\n",
    "\n",
    "num0 = 0\n",
    "num1 = 0\n",
    "for i in train_indices:\n",
    "    if labels[i] == '0':\n",
    "        num0 += 1\n",
    "    elif labels[i] == '1':\n",
    "        num1 += 1\n",
    "train_ratio = int(num0 / num1)\n",
    "\n",
    "num0 = 0\n",
    "num1 = 0\n",
    "for i in test_indices:\n",
    "    if labels[i] == '0':\n",
    "        num0 += 1\n",
    "    elif labels[i] == '1':\n",
    "        num1 += 1\n",
    "test_ratio = int(num0 / num1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#class_weight = {0 : 1.,\n",
    "#1: ratio}\n",
    "train_weight = {0 : 1.,\n",
    "1: train_ratio}\n",
    "\n",
    "test_weight = {0 : 1.,\n",
    "1: test_ratio}\n",
    "\n",
    "# fine-tune the model\n",
    "history = new_model.fit_generator(\n",
    "    image_generator(train_indices, minibatch_size),\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=epochs,\n",
    "    class_weight = train_weight\n",
    "    )\n",
    "\n",
    "history = new_model.fit_generator(\n",
    "    image_generator(test_indices, minibatch_size),\n",
    "    steps_per_epoch=test_steps,\n",
    "    epochs=epochs,\n",
    "    class_weight = test_weight\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "31/31 [==============================] - 30s - loss: 0.6433 - acc: 0.6931    \n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 11s - loss: 0.5559 - acc: 0.6812    \n"
     ]
    }
   ],
   "source": [
    "camera_num = '06'\n",
    "new_model = load_model('pca_camera_' + camera_num + '.hdf5')\n",
    "    \n",
    "# RMSprop\n",
    "#new_model.compile(loss='categorical_crossentropy',\n",
    "#              optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "new_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "\n",
    "minibatch_size = 64#64\n",
    "\n",
    "train_indices = np.load('pac_arrays/train_' + camera_num + '.npy')\n",
    "test_indices = np.load('pac_arrays/test_' + camera_num + '.npy')\n",
    "\n",
    "#image_generator(train_indices, minibatch_size)\n",
    "\n",
    "epochs = 1\n",
    "minibatch_size = 64#64\n",
    "\n",
    "train_steps = math.ceil(len(train_indices) / minibatch_size)\n",
    "test_steps = math.ceil(len(test_indices) / minibatch_size)\n",
    "\n",
    "num0 = 0\n",
    "num1 = 0\n",
    "for i in train_indices:\n",
    "    if labels[i] == '0':\n",
    "        num0 += 1\n",
    "    elif labels[i] == '1':\n",
    "        num1 += 1\n",
    "train_ratio = int(num0 / num1)\n",
    "\n",
    "num0 = 0\n",
    "num1 = 0\n",
    "for i in test_indices:\n",
    "    if labels[i] == '0':\n",
    "        num0 += 1\n",
    "    elif labels[i] == '1':\n",
    "        num1 += 1\n",
    "test_ratio = int(num0 / num1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#class_weight = {0 : 1.,\n",
    "#1: ratio}\n",
    "train_weight = {0 : 1.,\n",
    "1: train_ratio}\n",
    "\n",
    "test_weight = {0 : 1.,\n",
    "1: test_ratio}\n",
    "\n",
    "# fine-tune the model\n",
    "history = new_model.fit_generator(\n",
    "    image_generator(train_indices, minibatch_size),\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=epochs,\n",
    "    class_weight = train_weight\n",
    "    )\n",
    "\n",
    "history = new_model.fit_generator(\n",
    "    image_generator(test_indices, minibatch_size),\n",
    "    steps_per_epoch=test_steps,\n",
    "    epochs=epochs,\n",
    "    class_weight = test_weight\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "31/31 [==============================] - 31s - loss: 0.8768 - acc: 0.8229    \n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 11s - loss: 0.5580 - acc: 0.8721    \n"
     ]
    }
   ],
   "source": [
    "camera_num = '08'\n",
    "new_model = load_model('pca_camera_' + camera_num + '.hdf5')\n",
    "    \n",
    "# RMSprop\n",
    "#new_model.compile(loss='categorical_crossentropy',\n",
    "#              optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "new_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "\n",
    "minibatch_size = 64#64\n",
    "\n",
    "train_indices = np.load('pac_arrays/train_' + camera_num + '.npy')\n",
    "test_indices = np.load('pac_arrays/test_' + camera_num + '.npy')\n",
    "\n",
    "#image_generator(train_indices, minibatch_size)\n",
    "\n",
    "epochs = 1\n",
    "minibatch_size = 64#64\n",
    "\n",
    "train_steps = math.ceil(len(train_indices) / minibatch_size)\n",
    "test_steps = math.ceil(len(test_indices) / minibatch_size)\n",
    "\n",
    "num0 = 0\n",
    "num1 = 0\n",
    "for i in train_indices:\n",
    "    if labels[i] == '0':\n",
    "        num0 += 1\n",
    "    elif labels[i] == '1':\n",
    "        num1 += 1\n",
    "train_ratio = int(num0 / num1)\n",
    "\n",
    "num0 = 0\n",
    "num1 = 0\n",
    "for i in test_indices:\n",
    "    if labels[i] == '0':\n",
    "        num0 += 1\n",
    "    elif labels[i] == '1':\n",
    "        num1 += 1\n",
    "test_ratio = int(num0 / num1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#class_weight = {0 : 1.,\n",
    "#1: ratio}\n",
    "train_weight = {0 : 1.,\n",
    "1: train_ratio}\n",
    "\n",
    "test_weight = {0 : 1.,\n",
    "1: test_ratio}\n",
    "\n",
    "# fine-tune the model\n",
    "history = new_model.fit_generator(\n",
    "    image_generator(train_indices, minibatch_size),\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=epochs,\n",
    "    class_weight = train_weight\n",
    "    )\n",
    "\n",
    "history = new_model.fit_generator(\n",
    "    image_generator(test_indices, minibatch_size),\n",
    "    steps_per_epoch=test_steps,\n",
    "    epochs=epochs,\n",
    "    class_weight = test_weight\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "31/31 [==============================] - 31s - loss: 1.1246 - acc: 0.7587    \n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 11s - loss: 1.1986 - acc: 0.7403    \n"
     ]
    }
   ],
   "source": [
    "camera_num = '11'\n",
    "new_model = load_model('pca_camera_' + camera_num + '.hdf5')\n",
    "    \n",
    "# RMSprop\n",
    "#new_model.compile(loss='categorical_crossentropy',\n",
    "#              optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "new_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "\n",
    "minibatch_size = 64#64\n",
    "\n",
    "train_indices = np.load('pac_arrays/train_' + camera_num + '.npy')\n",
    "test_indices = np.load('pac_arrays/test_' + camera_num + '.npy')\n",
    "\n",
    "#image_generator(train_indices, minibatch_size)\n",
    "\n",
    "epochs = 1\n",
    "minibatch_size = 64#64\n",
    "\n",
    "train_steps = math.ceil(len(train_indices) / minibatch_size)\n",
    "test_steps = math.ceil(len(test_indices) / minibatch_size)\n",
    "\n",
    "num0 = 0\n",
    "num1 = 0\n",
    "for i in train_indices:\n",
    "    if labels[i] == '0':\n",
    "        num0 += 1\n",
    "    elif labels[i] == '1':\n",
    "        num1 += 1\n",
    "train_ratio = int(num0 / num1)\n",
    "\n",
    "num0 = 0\n",
    "num1 = 0\n",
    "for i in test_indices:\n",
    "    if labels[i] == '0':\n",
    "        num0 += 1\n",
    "    elif labels[i] == '1':\n",
    "        num1 += 1\n",
    "test_ratio = int(num0 / num1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#class_weight = {0 : 1.,\n",
    "#1: ratio}\n",
    "train_weight = {0 : 1.,\n",
    "1: train_ratio}\n",
    "\n",
    "test_weight = {0 : 1.,\n",
    "1: test_ratio}\n",
    "\n",
    "# fine-tune the model\n",
    "history = new_model.fit_generator(\n",
    "    image_generator(train_indices, minibatch_size),\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=epochs,\n",
    "    class_weight = train_weight\n",
    "    )\n",
    "\n",
    "history = new_model.fit_generator(\n",
    "    image_generator(test_indices, minibatch_size),\n",
    "    steps_per_epoch=test_steps,\n",
    "    epochs=epochs,\n",
    "    class_weight = test_weight\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "31/31 [==============================] - 31s - loss: 6.0743 - acc: 0.6674    \n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 11s - loss: 2.5017 - acc: 0.6315    \n"
     ]
    }
   ],
   "source": [
    "camera_num = '15'\n",
    "new_model = load_model('pca_camera_' + camera_num + '.hdf5')\n",
    "    \n",
    "# RMSprop\n",
    "#new_model.compile(loss='categorical_crossentropy',\n",
    "#              optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "new_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "\n",
    "minibatch_size = 64#64\n",
    "\n",
    "train_indices = np.load('pac_arrays/train_' + camera_num + '.npy')\n",
    "test_indices = np.load('pac_arrays/test_' + camera_num + '.npy')\n",
    "\n",
    "#image_generator(train_indices, minibatch_size)\n",
    "\n",
    "epochs = 1\n",
    "minibatch_size = 64#64\n",
    "\n",
    "train_steps = math.ceil(len(train_indices) / minibatch_size)\n",
    "test_steps = math.ceil(len(test_indices) / minibatch_size)\n",
    "\n",
    "num0 = 0\n",
    "num1 = 0\n",
    "for i in train_indices:\n",
    "    if labels[i] == '0':\n",
    "        num0 += 1\n",
    "    elif labels[i] == '1':\n",
    "        num1 += 1\n",
    "train_ratio = int(num0 / num1)\n",
    "\n",
    "num0 = 0\n",
    "num1 = 0\n",
    "for i in test_indices:\n",
    "    if labels[i] == '0':\n",
    "        num0 += 1\n",
    "    elif labels[i] == '1':\n",
    "        num1 += 1\n",
    "test_ratio = int(num0 / num1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#class_weight = {0 : 1.,\n",
    "#1: ratio}\n",
    "train_weight = {0 : 1.,\n",
    "1: train_ratio}\n",
    "\n",
    "test_weight = {0 : 1.,\n",
    "1: test_ratio}\n",
    "\n",
    "# fine-tune the model\n",
    "history = new_model.fit_generator(\n",
    "    image_generator(train_indices, minibatch_size),\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=epochs,\n",
    "    class_weight = train_weight\n",
    "    )\n",
    "\n",
    "history = new_model.fit_generator(\n",
    "    image_generator(test_indices, minibatch_size),\n",
    "    steps_per_epoch=test_steps,\n",
    "    epochs=epochs,\n",
    "    class_weight = test_weight\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "31/31 [==============================] - 31s - loss: 0.6770 - acc: 0.7732    \n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 11s - loss: 0.6240 - acc: 0.7809    \n"
     ]
    }
   ],
   "source": [
    "camera_num = '23'\n",
    "new_model = load_model('pca_camera_' + camera_num + '.hdf5')\n",
    "    \n",
    "# RMSprop\n",
    "#new_model.compile(loss='categorical_crossentropy',\n",
    "#              optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "new_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "\n",
    "minibatch_size = 64#64\n",
    "\n",
    "train_indices = np.load('pac_arrays/train_' + camera_num + '.npy')\n",
    "test_indices = np.load('pac_arrays/test_' + camera_num + '.npy')\n",
    "\n",
    "#image_generator(train_indices, minibatch_size)\n",
    "\n",
    "epochs = 1\n",
    "minibatch_size = 64#64\n",
    "\n",
    "train_steps = math.ceil(len(train_indices) / minibatch_size)\n",
    "test_steps = math.ceil(len(test_indices) / minibatch_size)\n",
    "\n",
    "num0 = 0\n",
    "num1 = 0\n",
    "for i in train_indices:\n",
    "    if labels[i] == '0':\n",
    "        num0 += 1\n",
    "    elif labels[i] == '1':\n",
    "        num1 += 1\n",
    "train_ratio = int(num0 / num1)\n",
    "\n",
    "num0 = 0\n",
    "num1 = 0\n",
    "for i in test_indices:\n",
    "    if labels[i] == '0':\n",
    "        num0 += 1\n",
    "    elif labels[i] == '1':\n",
    "        num1 += 1\n",
    "test_ratio = int(num0 / num1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#class_weight = {0 : 1.,\n",
    "#1: ratio}\n",
    "train_weight = {0 : 1.,\n",
    "1: train_ratio}\n",
    "\n",
    "test_weight = {0 : 1.,\n",
    "1: test_ratio}\n",
    "\n",
    "# fine-tune the model\n",
    "history = new_model.fit_generator(\n",
    "    image_generator(train_indices, minibatch_size),\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=epochs,\n",
    "    class_weight = train_weight\n",
    "    )\n",
    "\n",
    "history = new_model.fit_generator(\n",
    "    image_generator(test_indices, minibatch_size),\n",
    "    steps_per_epoch=test_steps,\n",
    "    epochs=epochs,\n",
    "    class_weight = test_weight\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "31/31 [==============================] - 31s - loss: 3.1614 - acc: 0.6425    \n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 11s - loss: 1.0874 - acc: 0.7394    \n"
     ]
    }
   ],
   "source": [
    "camera_num = '39'\n",
    "new_model = load_model('pca_camera_' + camera_num + '.hdf5')\n",
    "    \n",
    "# RMSprop\n",
    "#new_model.compile(loss='categorical_crossentropy',\n",
    "#              optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "new_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "\n",
    "minibatch_size = 64#64\n",
    "\n",
    "train_indices = np.load('pac_arrays/train_' + camera_num + '.npy')\n",
    "test_indices = np.load('pac_arrays/test_' + camera_num + '.npy')\n",
    "\n",
    "#image_generator(train_indices, minibatch_size)\n",
    "\n",
    "epochs = 1\n",
    "minibatch_size = 64#64\n",
    "\n",
    "train_steps = math.ceil(len(train_indices) / minibatch_size)\n",
    "test_steps = math.ceil(len(test_indices) / minibatch_size)\n",
    "\n",
    "num0 = 0\n",
    "num1 = 0\n",
    "for i in train_indices:\n",
    "    if labels[i] == '0':\n",
    "        num0 += 1\n",
    "    elif labels[i] == '1':\n",
    "        num1 += 1\n",
    "train_ratio = int(num0 / num1)\n",
    "\n",
    "num0 = 0\n",
    "num1 = 0\n",
    "for i in test_indices:\n",
    "    if labels[i] == '0':\n",
    "        num0 += 1\n",
    "    elif labels[i] == '1':\n",
    "        num1 += 1\n",
    "test_ratio = int(num0 / num1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#class_weight = {0 : 1.,\n",
    "#1: ratio}\n",
    "train_weight = {0 : 1.,\n",
    "1: train_ratio}\n",
    "\n",
    "test_weight = {0 : 1.,\n",
    "1: test_ratio}\n",
    "\n",
    "# fine-tune the model\n",
    "history = new_model.fit_generator(\n",
    "    image_generator(train_indices, minibatch_size),\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=epochs,\n",
    "    class_weight = train_weight\n",
    "    )\n",
    "\n",
    "history = new_model.fit_generator(\n",
    "    image_generator(test_indices, minibatch_size),\n",
    "    steps_per_epoch=test_steps,\n",
    "    epochs=epochs,\n",
    "    class_weight = test_weight\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 6\n",
      "Epoch 1/1\n",
      "31/31 [==============================] - 31s - loss: 1.0828 - acc: 0.6977    \n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 11s - loss: 1.0944 - acc: 0.6536    \n"
     ]
    }
   ],
   "source": [
    "camera_num = '52'\n",
    "new_model = load_model('pca_camera_' + camera_num + '.hdf5')\n",
    "    \n",
    "# RMSprop\n",
    "#new_model.compile(loss='categorical_crossentropy',\n",
    "#              optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "new_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "\n",
    "minibatch_size = 64#64\n",
    "\n",
    "train_indices = np.load('pac_arrays/train_' + camera_num + '.npy')\n",
    "test_indices = np.load('pac_arrays/test_' + camera_num + '.npy')\n",
    "\n",
    "#image_generator(train_indices, minibatch_size)\n",
    "\n",
    "epochs = 1\n",
    "minibatch_size = 64#64\n",
    "\n",
    "train_steps = math.ceil(len(train_indices) / minibatch_size)\n",
    "test_steps = math.ceil(len(test_indices) / minibatch_size)\n",
    "\n",
    "num0 = 0\n",
    "num1 = 0\n",
    "for i in train_indices:\n",
    "    if labels[i] == '0':\n",
    "        num0 += 1\n",
    "    elif labels[i] == '1':\n",
    "        num1 += 1\n",
    "train_ratio = int(num0 / num1)\n",
    "\n",
    "num0 = 0\n",
    "num1 = 0\n",
    "for i in test_indices:\n",
    "    if labels[i] == '0':\n",
    "        num0 += 1\n",
    "    elif labels[i] == '1':\n",
    "        num1 += 1\n",
    "test_ratio = int(num0 / num1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#class_weight = {0 : 1.,\n",
    "#1: ratio}\n",
    "train_weight = {0 : 1.,\n",
    "1: train_ratio}\n",
    "\n",
    "test_weight = {0 : 1.,\n",
    "1: test_ratio}\n",
    "\n",
    "print(train_ratio, test_ratio)\n",
    "\n",
    "# fine-tune the model\n",
    "history = new_model.fit_generator(\n",
    "    image_generator(train_indices, minibatch_size),\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=epochs,\n",
    "    class_weight = train_weight\n",
    "    )\n",
    "\n",
    "history = new_model.fit_generator(\n",
    "    image_generator(test_indices, minibatch_size),\n",
    "    steps_per_epoch=test_steps,\n",
    "    epochs=epochs,\n",
    "    class_weight = test_weight\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 65\n",
      "Epoch 1/1\n",
      "31/31 [==============================] - 31s - loss: 2.0904 - acc: 0.6793    \n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 11s - loss: 1.1743 - acc: 0.7027    \n"
     ]
    }
   ],
   "source": [
    "camera_num = '59'\n",
    "new_model = load_model('pca_camera_' + camera_num + '.hdf5')\n",
    "    \n",
    "# RMSprop\n",
    "#new_model.compile(loss='categorical_crossentropy',\n",
    "#              optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "new_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "\n",
    "minibatch_size = 64#64\n",
    "\n",
    "train_indices = np.load('pac_arrays/train_' + camera_num + '.npy')\n",
    "test_indices = np.load('pac_arrays/test_' + camera_num + '.npy')\n",
    "\n",
    "#image_generator(train_indices, minibatch_size)\n",
    "\n",
    "epochs = 1\n",
    "minibatch_size = 64#64\n",
    "\n",
    "train_steps = math.ceil(len(train_indices) / minibatch_size)\n",
    "test_steps = math.ceil(len(test_indices) / minibatch_size)\n",
    "\n",
    "num0 = 0\n",
    "num1 = 0\n",
    "for i in train_indices:\n",
    "    if labels[i] == '0':\n",
    "        num0 += 1\n",
    "    elif labels[i] == '1':\n",
    "        num1 += 1\n",
    "train_ratio = int(num0 / num1)\n",
    "\n",
    "num0 = 0\n",
    "num1 = 0\n",
    "for i in test_indices:\n",
    "    if labels[i] == '0':\n",
    "        num0 += 1\n",
    "    elif labels[i] == '1':\n",
    "        num1 += 1\n",
    "test_ratio = int(num0 / num1)\n",
    "\n",
    "print(train_ratio, test_ratio)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#class_weight = {0 : 1.,\n",
    "#1: ratio}\n",
    "train_weight = {0 : 1.,\n",
    "1: train_ratio}\n",
    "\n",
    "test_weight = {0 : 1.,\n",
    "1: test_ratio}\n",
    "\n",
    "# fine-tune the model\n",
    "history = new_model.fit_generator(\n",
    "    image_generator(train_indices, minibatch_size),\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=epochs,\n",
    "    class_weight = train_weight\n",
    "    )\n",
    "\n",
    "history = new_model.fit_generator(\n",
    "    image_generator(test_indices, minibatch_size),\n",
    "    steps_per_epoch=test_steps,\n",
    "    epochs=epochs,\n",
    "    class_weight = test_weight\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3\n",
      "Epoch 1/1\n",
      "31/31 [==============================] - 31s - loss: 0.8433 - acc: 0.7461    \n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 11s - loss: 0.7543 - acc: 0.7516    \n"
     ]
    }
   ],
   "source": [
    "camera_num = '62'\n",
    "new_model = load_model('pca_camera_' + camera_num + '.hdf5')\n",
    "    \n",
    "# RMSprop\n",
    "#new_model.compile(loss='categorical_crossentropy',\n",
    "#              optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "new_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "\n",
    "minibatch_size = 64#64\n",
    "\n",
    "train_indices = np.load('pac_arrays/train_' + camera_num + '.npy')\n",
    "test_indices = np.load('pac_arrays/test_' + camera_num + '.npy')\n",
    "\n",
    "#image_generator(train_indices, minibatch_size)\n",
    "\n",
    "epochs = 1\n",
    "minibatch_size = 64#64\n",
    "\n",
    "train_steps = math.ceil(len(train_indices) / minibatch_size)\n",
    "test_steps = math.ceil(len(test_indices) / minibatch_size)\n",
    "\n",
    "num0 = 0\n",
    "num1 = 0\n",
    "for i in train_indices:\n",
    "    if labels[i] == '0':\n",
    "        num0 += 1\n",
    "    elif labels[i] == '1':\n",
    "        num1 += 1\n",
    "train_ratio = int(num0 / num1)\n",
    "\n",
    "num0 = 0\n",
    "num1 = 0\n",
    "for i in test_indices:\n",
    "    if labels[i] == '0':\n",
    "        num0 += 1\n",
    "    elif labels[i] == '1':\n",
    "        num1 += 1\n",
    "test_ratio = int(num0 / num1)\n",
    "\n",
    "\n",
    "print(train_ratio, test_ratio)\n",
    "\n",
    "\n",
    "#class_weight = {0 : 1.,\n",
    "#1: ratio}\n",
    "train_weight = {0 : 1.,\n",
    "1: train_ratio}\n",
    "\n",
    "test_weight = {0 : 1.,\n",
    "1: test_ratio}\n",
    "\n",
    "# fine-tune the model\n",
    "history = new_model.fit_generator(\n",
    "    image_generator(train_indices, minibatch_size),\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=epochs,\n",
    "    class_weight = train_weight\n",
    "    )\n",
    "\n",
    "history = new_model.fit_generator(\n",
    "    image_generator(test_indices, minibatch_size),\n",
    "    steps_per_epoch=test_steps,\n",
    "    epochs=epochs,\n",
    "    class_weight = test_weight\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2\n",
      "Epoch 1/1\n",
      "31/31 [==============================] - 44s - loss: 0.9023 - acc: 0.6594    \n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 17s - loss: 0.7945 - acc: 0.6480    \n"
     ]
    }
   ],
   "source": [
    "camera_num = '63'\n",
    "new_model = load_model('pca_camera_' + camera_num + '.hdf5')\n",
    "    \n",
    "# RMSprop\n",
    "#new_model.compile(loss='categorical_crossentropy',\n",
    "#              optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "new_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "\n",
    "minibatch_size = 64#64\n",
    "\n",
    "train_indices = np.load('pac_arrays/train_' + camera_num + '.npy')\n",
    "test_indices = np.load('pac_arrays/test_' + camera_num + '.npy')\n",
    "\n",
    "#image_generator(train_indices, minibatch_size)\n",
    "\n",
    "epochs = 1\n",
    "minibatch_size = 64#64\n",
    "\n",
    "train_steps = math.ceil(len(train_indices) / minibatch_size)\n",
    "test_steps = math.ceil(len(test_indices) / minibatch_size)\n",
    "\n",
    "num0 = 0\n",
    "num1 = 0\n",
    "for i in train_indices:\n",
    "    if labels[i] == '0':\n",
    "        num0 += 1\n",
    "    elif labels[i] == '1':\n",
    "        num1 += 1\n",
    "train_ratio = int(num0 / num1)\n",
    "\n",
    "num0 = 0\n",
    "num1 = 0\n",
    "for i in test_indices:\n",
    "    if labels[i] == '0':\n",
    "        num0 += 1\n",
    "    elif labels[i] == '1':\n",
    "        num1 += 1\n",
    "test_ratio = int(num0 / num1)\n",
    "\n",
    "\n",
    "print(train_ratio, test_ratio)\n",
    "\n",
    "\n",
    "#class_weight = {0 : 1.,\n",
    "#1: ratio}\n",
    "train_weight = {0 : 1.,\n",
    "1: train_ratio}\n",
    "\n",
    "test_weight = {0 : 1.,\n",
    "1: test_ratio}\n",
    "\n",
    "# fine-tune the model\n",
    "history = new_model.fit_generator(\n",
    "    image_generator(train_indices, minibatch_size),\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=epochs,\n",
    "    class_weight = train_weight\n",
    "    )\n",
    "\n",
    "history = new_model.fit_generator(\n",
    "    image_generator(test_indices, minibatch_size),\n",
    "    steps_per_epoch=test_steps,\n",
    "    epochs=epochs,\n",
    "    class_weight = test_weight\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2\n",
      "Epoch 1/1\n",
      "31/31 [==============================] - 30s - loss: 0.9471 - acc: 0.6253    \n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 11s - loss: 0.9245 - acc: 0.6163    \n"
     ]
    }
   ],
   "source": [
    "camera_num = '72'\n",
    "new_model = load_model('pca_camera_' + camera_num + '.hdf5')\n",
    "    \n",
    "# RMSprop\n",
    "#new_model.compile(loss='categorical_crossentropy',\n",
    "#              optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "new_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "\n",
    "minibatch_size = 64#64\n",
    "\n",
    "train_indices = np.load('pac_arrays/train_' + camera_num + '.npy')\n",
    "test_indices = np.load('pac_arrays/test_' + camera_num + '.npy')\n",
    "\n",
    "#image_generator(train_indices, minibatch_size)\n",
    "\n",
    "epochs = 1\n",
    "minibatch_size = 64#64\n",
    "\n",
    "train_steps = math.ceil(len(train_indices) / minibatch_size)\n",
    "test_steps = math.ceil(len(test_indices) / minibatch_size)\n",
    "\n",
    "num0 = 0\n",
    "num1 = 0\n",
    "for i in train_indices:\n",
    "    if labels[i] == '0':\n",
    "        num0 += 1\n",
    "    elif labels[i] == '1':\n",
    "        num1 += 1\n",
    "train_ratio = int(num0 / num1)\n",
    "\n",
    "num0 = 0\n",
    "num1 = 0\n",
    "for i in test_indices:\n",
    "    if labels[i] == '0':\n",
    "        num0 += 1\n",
    "    elif labels[i] == '1':\n",
    "        num1 += 1\n",
    "test_ratio = int(num0 / num1)\n",
    "\n",
    "\n",
    "print(train_ratio, test_ratio)\n",
    "\n",
    "\n",
    "#class_weight = {0 : 1.,\n",
    "#1: ratio}\n",
    "train_weight = {0 : 1.,\n",
    "1: train_ratio}\n",
    "\n",
    "test_weight = {0 : 1.,\n",
    "1: test_ratio}\n",
    "\n",
    "# fine-tune the model\n",
    "history = new_model.fit_generator(\n",
    "    image_generator(train_indices, minibatch_size),\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=epochs,\n",
    "    class_weight = train_weight\n",
    "    )\n",
    "\n",
    "history = new_model.fit_generator(\n",
    "    image_generator(test_indices, minibatch_size),\n",
    "    steps_per_epoch=test_steps,\n",
    "    epochs=epochs,\n",
    "    class_weight = test_weight\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
