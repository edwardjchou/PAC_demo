{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from keras import applications\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Input\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import color\n",
    "from skimage.transform import resize\n",
    "\n",
    "from IPython.display import Audio\n",
    "from IPython.display import display\n",
    "import time\n",
    "\n",
    "files = ['02', '04', '06', '08', '11', '15', '23', '39', '52', '59', '62', '63', '72']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"pac_transform_guide.csv\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    i = 0\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for ind, row in enumerate(reader):\n",
    "        index = row[0]\n",
    "        filename = row[1]\n",
    "        label = row[2]\n",
    "        image_paths.append(filename)\n",
    "        labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: 02\n",
      "1829\n",
      "/pac_augmented/train_02_ocean/0/0.png\n",
      "/pac_augmented/train_02_ocean/0/1828.png\n",
      "151\n",
      "/pac_augmented/train_02_ocean/1/0.png\n",
      "/pac_augmented/train_02_ocean/1/150.png\n",
      "1812\n",
      "/pac_augmented/train_02_ocean/transforms/0_0.png\n",
      "/pac_augmented/train_02_ocean/transforms/150_11.png\n",
      "/pac_augmented/test_02_ocean/0/0.png\n",
      "/pac_augmented/test_02_ocean/0/602.png\n",
      "/pac_augmented/test_02_ocean/1/0.png\n",
      "/pac_augmented/test_02_ocean/1/56.png\n",
      "File: 04\n",
      "1783\n",
      "/pac_augmented/train_04_ocean/0/0.png\n",
      "/pac_augmented/train_04_ocean/0/1782.png\n",
      "197\n",
      "/pac_augmented/train_04_ocean/1/0.png\n",
      "/pac_augmented/train_04_ocean/1/196.png\n",
      "1773\n",
      "/pac_augmented/train_04_ocean/transforms/0_0.png\n",
      "/pac_augmented/train_04_ocean/transforms/196_8.png\n",
      "/pac_augmented/test_04_ocean/0/0.png\n",
      "/pac_augmented/test_04_ocean/0/598.png\n",
      "/pac_augmented/test_04_ocean/1/0.png\n",
      "/pac_augmented/test_04_ocean/1/60.png\n",
      "File: 06\n",
      "1240\n",
      "/pac_augmented/train_06_ocean/0/0.png\n",
      "/pac_augmented/train_06_ocean/0/1239.png\n",
      "740\n",
      "/pac_augmented/train_06_ocean/1/0.png\n",
      "/pac_augmented/train_06_ocean/1/739.png\n",
      "740\n",
      "/pac_augmented/train_06_ocean/transforms/0_0.png\n",
      "/pac_augmented/train_06_ocean/transforms/739_0.png\n",
      "/pac_augmented/test_06_ocean/0/0.png\n",
      "/pac_augmented/test_06_ocean/0/405.png\n",
      "/pac_augmented/test_06_ocean/1/0.png\n",
      "/pac_augmented/test_06_ocean/1/253.png\n",
      "File: 08\n",
      "1766\n",
      "/pac_augmented/train_08_ocean/0/0.png\n",
      "/pac_augmented/train_08_ocean/0/1765.png\n",
      "214\n",
      "/pac_augmented/train_08_ocean/1/0.png\n",
      "/pac_augmented/train_08_ocean/1/213.png\n",
      "1712\n",
      "/pac_augmented/train_08_ocean/transforms/0_0.png\n",
      "/pac_augmented/train_08_ocean/transforms/213_7.png\n",
      "/pac_augmented/test_08_ocean/0/0.png\n",
      "/pac_augmented/test_08_ocean/0/593.png\n",
      "/pac_augmented/test_08_ocean/1/0.png\n",
      "/pac_augmented/test_08_ocean/1/65.png\n",
      "File: 11\n",
      "1883\n",
      "/pac_augmented/train_11_ocean/0/0.png\n",
      "/pac_augmented/train_11_ocean/0/1882.png\n",
      "97\n",
      "/pac_augmented/train_11_ocean/1/0.png\n",
      "/pac_augmented/train_11_ocean/1/96.png\n",
      "1843\n",
      "/pac_augmented/train_11_ocean/transforms/0_0.png\n",
      "/pac_augmented/train_11_ocean/transforms/96_18.png\n",
      "/pac_augmented/test_11_ocean/0/0.png\n",
      "/pac_augmented/test_11_ocean/0/634.png\n",
      "/pac_augmented/test_11_ocean/1/0.png\n",
      "/pac_augmented/test_11_ocean/1/24.png\n",
      "File: 15\n",
      "1976\n",
      "/pac_augmented/train_15_ocean/0/0.png\n",
      "/pac_augmented/train_15_ocean/0/1975.png\n",
      "4\n",
      "/pac_augmented/train_15_ocean/1/0.png\n",
      "/pac_augmented/train_15_ocean/1/3.png\n",
      "1976\n",
      "/pac_augmented/train_15_ocean/transforms/0_0.png\n",
      "/pac_augmented/train_15_ocean/transforms/3_493.png\n",
      "/pac_augmented/test_15_ocean/0/0.png\n",
      "/pac_augmented/test_15_ocean/0/656.png\n",
      "/pac_augmented/test_15_ocean/1/0.png\n",
      "/pac_augmented/test_15_ocean/1/2.png\n",
      "File: 23\n",
      "1486\n",
      "/pac_augmented/train_23_ocean/0/0.png\n",
      "/pac_augmented/train_23_ocean/0/1485.png\n",
      "494\n",
      "/pac_augmented/train_23_ocean/1/0.png\n",
      "/pac_augmented/train_23_ocean/1/493.png\n",
      "1482\n",
      "/pac_augmented/train_23_ocean/transforms/0_0.png\n",
      "/pac_augmented/train_23_ocean/transforms/493_2.png\n",
      "/pac_augmented/test_23_ocean/0/0.png\n",
      "/pac_augmented/test_23_ocean/0/513.png\n",
      "/pac_augmented/test_23_ocean/1/0.png\n",
      "/pac_augmented/test_23_ocean/1/145.png\n",
      "File: 39\n",
      "1967\n",
      "/pac_augmented/train_39_ocean/0/0.png\n",
      "/pac_augmented/train_39_ocean/0/1966.png\n",
      "13\n",
      "/pac_augmented/train_39_ocean/1/0.png\n",
      "/pac_augmented/train_39_ocean/1/12.png\n",
      "1963\n",
      "/pac_augmented/train_39_ocean/transforms/0_0.png\n",
      "/pac_augmented/train_39_ocean/transforms/12_150.png\n",
      "/pac_augmented/test_39_ocean/0/0.png\n",
      "/pac_augmented/test_39_ocean/0/653.png\n",
      "/pac_augmented/test_39_ocean/1/0.png\n",
      "/pac_augmented/test_39_ocean/1/5.png\n",
      "File: 52\n",
      "1696\n",
      "/pac_augmented/train_52_ocean/0/0.png\n",
      "/pac_augmented/train_52_ocean/0/1695.png\n",
      "284\n",
      "/pac_augmented/train_52_ocean/1/0.png\n",
      "/pac_augmented/train_52_ocean/1/283.png\n",
      "1420\n",
      "/pac_augmented/train_52_ocean/transforms/0_0.png\n",
      "/pac_augmented/train_52_ocean/transforms/283_4.png\n",
      "/pac_augmented/test_52_ocean/0/0.png\n",
      "/pac_augmented/test_52_ocean/0/567.png\n",
      "/pac_augmented/test_52_ocean/1/0.png\n",
      "/pac_augmented/test_52_ocean/1/91.png\n",
      "File: 59\n",
      "1953\n",
      "/pac_augmented/train_59_ocean/0/0.png\n",
      "/pac_augmented/train_59_ocean/0/1952.png\n",
      "27\n",
      "/pac_augmented/train_59_ocean/1/0.png\n",
      "/pac_augmented/train_59_ocean/1/26.png\n",
      "1944\n",
      "/pac_augmented/train_59_ocean/transforms/0_0.png\n",
      "/pac_augmented/train_59_ocean/transforms/26_71.png\n",
      "/pac_augmented/test_59_ocean/0/0.png\n",
      "/pac_augmented/test_59_ocean/0/649.png\n",
      "/pac_augmented/test_59_ocean/1/0.png\n",
      "/pac_augmented/test_59_ocean/1/9.png\n",
      "File: 62\n",
      "1545\n",
      "/pac_augmented/train_62_ocean/0/0.png\n",
      "/pac_augmented/train_62_ocean/0/1544.png\n",
      "435\n",
      "/pac_augmented/train_62_ocean/1/0.png\n",
      "/pac_augmented/train_62_ocean/1/434.png\n",
      "1305\n",
      "/pac_augmented/train_62_ocean/transforms/0_0.png\n",
      "/pac_augmented/train_62_ocean/transforms/434_2.png\n",
      "/pac_augmented/test_62_ocean/0/0.png\n",
      "/pac_augmented/test_62_ocean/0/496.png\n",
      "/pac_augmented/test_62_ocean/1/0.png\n",
      "/pac_augmented/test_62_ocean/1/162.png\n",
      "File: 63\n",
      "1397\n",
      "/pac_augmented/train_63_ocean/0/0.png\n",
      "/pac_augmented/train_63_ocean/0/1396.png\n",
      "583\n",
      "/pac_augmented/train_63_ocean/1/0.png\n",
      "/pac_augmented/train_63_ocean/1/582.png\n",
      "1166\n",
      "/pac_augmented/train_63_ocean/transforms/0_0.png\n",
      "/pac_augmented/train_63_ocean/transforms/582_1.png\n",
      "/pac_augmented/test_63_ocean/0/0.png\n",
      "/pac_augmented/test_63_ocean/0/450.png\n",
      "/pac_augmented/test_63_ocean/1/0.png\n",
      "/pac_augmented/test_63_ocean/1/208.png\n",
      "File: 72\n",
      "1433\n",
      "/pac_augmented/train_72_ocean/0/0.png\n",
      "/pac_augmented/train_72_ocean/0/1432.png\n",
      "547\n",
      "/pac_augmented/train_72_ocean/1/0.png\n",
      "/pac_augmented/train_72_ocean/1/546.png\n",
      "1094\n",
      "/pac_augmented/train_72_ocean/transforms/0_0.png\n",
      "/pac_augmented/train_72_ocean/transforms/546_1.png\n",
      "/pac_augmented/test_72_ocean/0/0.png\n",
      "/pac_augmented/test_72_ocean/0/476.png\n",
      "/pac_augmented/test_72_ocean/1/0.png\n",
      "/pac_augmented/test_72_ocean/1/182.png\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    print('File: ' + file)\n",
    "    train_0 = np.load('pac_augment_arrays/ocean_0_train_' + file + '.npy')\n",
    "    print(len(train_0))\n",
    "    print(image_paths[min(train_0)])\n",
    "    print(image_paths[max(train_0)])\n",
    "\n",
    "    train_1 = np.load('pac_augment_arrays/ocean_1_train_' + file + '.npy')\n",
    "    print(len(train_1))\n",
    "    print(image_paths[min(train_1)])\n",
    "    print(image_paths[max(train_1)])\n",
    "    \n",
    "    train_transforms = np.load('pac_augment_arrays/ocean_transforms_train_' + file + '.npy')\n",
    "    print(len(train_transforms))\n",
    "    print(image_paths[min(train_transforms)])\n",
    "    print(image_paths[max(train_transforms)])\n",
    "    \n",
    "    test_0 = np.load('pac_augment_arrays/ocean_0_test_' + file + '.npy')\n",
    "    print(image_paths[min(test_0)])\n",
    "    print(image_paths[max(test_0)])\n",
    "    \n",
    "    test_1 = np.load('pac_augment_arrays/ocean_1_test_' + file + '.npy')\n",
    "    print(image_paths[min(test_1)])\n",
    "    print(image_paths[max(test_1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1433\n",
      "547\n",
      "1980\n"
     ]
    }
   ],
   "source": [
    "print(len(train_0))\n",
    "print(len(train_1))\n",
    "print(len(np.concatenate([train_0, train_1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_generator(indices, batch_size):\n",
    "\n",
    "    num_batches = int(len(indices) / batch_size)\n",
    "    \n",
    "    while True:\n",
    "        for batch_i in range(num_batches):\n",
    "            if batch_i == num_batches - 1:\n",
    "                # special case: return as many as possible\n",
    "                start_i = batch_i * batch_size\n",
    "                batch_indices = indices[start_i:]\n",
    "                \n",
    "                X = np.zeros((len(batch_indices), 224, 224, 3))\n",
    "                Y = np.zeros((len(batch_indices), 2)) # Change to one-hot\n",
    "            \n",
    "            else:\n",
    "                start_i = batch_i * batch_size\n",
    "                end_i = start_i + batch_size\n",
    "\n",
    "                batch_indices = indices[start_i:end_i]\n",
    "\n",
    "                X = np.zeros((batch_size, 224, 224, 3))\n",
    "                Y = np.zeros((batch_size, 2)) # Change to one-hot\n",
    "            \n",
    "            for i, index in enumerate(batch_indices):\n",
    "                #img = image.load_img(image_paths[index], target_size=(224, 224))\n",
    "                '''\n",
    "                data = np.load(image_paths[int(index)])\n",
    "                depth_map = data['x'].astype(np.float32)\n",
    "                orig_img, ocean = depth_map_to_image(depth_map)\n",
    "                '''\n",
    "                ocean = image.load_img(image_paths[index], target_size=(224, 224))\n",
    "                #ocean = resize(ocean, (224, 224), mode='constant')\n",
    "                \n",
    "                X[i, :, :, :] = ocean\n",
    "                # Convert to 1 hot vector\n",
    "                one_hot = np.zeros(2)\n",
    "                sanitation_label = labels[int(index)]\n",
    "                if sanitation_label == '0':\n",
    "                    one_hot[0] = 1\n",
    "                elif sanitation_label == '1':\n",
    "                    one_hot[1] = 1\n",
    "                Y[i,:] = one_hot\n",
    "            \n",
    "            # use vgg16 preprocessing\n",
    "            X = preprocess_input(X)\n",
    "            \n",
    "            yield (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def camera_model(camera_num):\n",
    "    print(camera_num)\n",
    "    input_tensor = Input(shape=(224,224,3))\n",
    "    model = applications.VGG16(weights='imagenet', include_top=False, input_tensor = input_tensor)\n",
    "    \n",
    "    # build a classifier model to put on top of the convolutional model\n",
    "    x = model.output\n",
    "    x = Flatten(input_shape=(model.output_shape[1:]))(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    x = Dropout(0.05)(x)\n",
    "    x = Dense(256, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
    "    x = Dense(2, activation='softmax', name='output', kernel_initializer='glorot_uniform')(x)\n",
    "\n",
    "    # add new classifier model on top of convolutional base\n",
    "    new_model = Model(model.input, x)\n",
    "    \n",
    "    for layer in new_model.layers[:19]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    #new_model = load_model('pca_camera_' + camera_num + '.hdf5')\n",
    "    \n",
    "    # RMSprop\n",
    "    #new_model.compile(loss='categorical_crossentropy',\n",
    "    #              optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "    new_model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "\n",
    "    minibatch_size = 64#64\n",
    "    \n",
    "    train_0 = np.load('pac_augment_arrays/ocean_0_train_' + camera_num + '.npy')\n",
    "    train_transforms = np.load('pac_augment_arrays/ocean_transforms_train_' + camera_num + '.npy')\n",
    "    train_indices = np.random.permutation(np.concatenate([train_0, train_transforms]))\n",
    "    test_0 = np.load('pac_augment_arrays/ocean_0_test_' + camera_num + '.npy')\n",
    "    test_1 = np.load('pac_augment_arrays/ocean_1_test_' + camera_num + '.npy')\n",
    "    test_indices = np.random.permutation(np.concatenate([test_0, test_1]))\n",
    "    \n",
    "    print(len(train_indices))\n",
    "    print(len(test_indices))\n",
    "\n",
    "    \n",
    "\n",
    "    #train_indices =     \n",
    "    #test_indices = np.load('pac_arrays/test_' + camera_num + '.npy')\n",
    "\n",
    "    image_generator(train_indices, minibatch_size)\n",
    "\n",
    "    epochs = 10\n",
    "    minibatch_size = 64#64\n",
    "\n",
    "    train_steps = math.ceil(len(train_indices) / minibatch_size)\n",
    "    test_steps = math.ceil(len(test_indices) / minibatch_size)\n",
    "    \n",
    "    num0 = 0\n",
    "    num1 = 0\n",
    "    for i in train_indices:\n",
    "        if labels[i] == '0':\n",
    "            num0 += 1\n",
    "        elif labels[i] == '1':\n",
    "            num1 += 1\n",
    "    ratio = int(num0 / num1)\n",
    "    print(ratio)\n",
    "    \n",
    "    num0 = 0\n",
    "    num1 = 0\n",
    "    for i in test_indices:\n",
    "        if labels[i] == '0':\n",
    "            num0 += 1\n",
    "        elif labels[i] == '1':\n",
    "            num1 += 1\n",
    "    ratio = int(num0 / num1)\n",
    "    print(ratio)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    #class_weight = {0 : 1.,\n",
    "    #1: ratio}\n",
    "    class_weight = {0 : 1.,\n",
    "    1: ratio}\n",
    "\n",
    "    # fine-tune the model\n",
    "    history = new_model.fit_generator(\n",
    "        image_generator(train_indices, minibatch_size),\n",
    "        steps_per_epoch=train_steps,\n",
    "        epochs=epochs,\n",
    "        validation_data=image_generator(test_indices, minibatch_size),\n",
    "        nb_val_samples=test_steps)\n",
    "\n",
    "    new_model.save('pca_augment_camera_' + camera_num + '.hdf5')\n",
    "    \n",
    "    test_epochs = 1\n",
    "\n",
    "    history = new_model.fit_generator(\n",
    "        image_generator(test_indices, minibatch_size),\n",
    "        steps_per_epoch=test_steps,\n",
    "        epochs=test_epochs,\n",
    "        class_weight = class_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02\n",
      "3641\n",
      "660\n",
      "1\n",
      "10\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:87: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:87: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_steps=11, epochs=10, steps_per_epoch=57, validation_data=<generator...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 69s - loss: 0.4926 - acc: 0.9593 - val_loss: 0.5594 - val_acc: 0.9599\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 69s - loss: 0.2121 - acc: 0.9842 - val_loss: 0.3876 - val_acc: 0.9738\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 69s - loss: 0.2005 - acc: 0.9846 - val_loss: 0.3789 - val_acc: 0.9751\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 68s - loss: 0.1678 - acc: 0.9867 - val_loss: 0.2973 - val_acc: 0.9793\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 68s - loss: 0.1609 - acc: 0.9878 - val_loss: 0.3705 - val_acc: 0.9751\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 68s - loss: 0.1297 - acc: 0.9905 - val_loss: 0.5178 - val_acc: 0.9641\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 69s - loss: 0.1191 - acc: 0.9916 - val_loss: 0.3112 - val_acc: 0.9793\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 68s - loss: 0.0985 - acc: 0.9934 - val_loss: 0.3039 - val_acc: 0.9793\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 68s - loss: 0.1003 - acc: 0.9934 - val_loss: 0.7503 - val_acc: 0.9503\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 69s - loss: 0.0768 - acc: 0.9948 - val_loss: 0.2846 - val_acc: 0.9812\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 11s - loss: 3.1002 - acc: 0.9601    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "camera_model('02')\n",
    "#for camera_num in camera_nums:\n",
    "#    camera_model(camera_num)\n",
    "sound_file = 'http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav'\n",
    "display(Audio(url=sound_file, autoplay=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04\n",
      "3556\n",
      "660\n",
      "1\n",
      "9\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:87: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:87: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_steps=11, epochs=10, steps_per_epoch=56, validation_data=<generator...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 75s - loss: 0.4203 - acc: 0.9636 - val_loss: 0.5296 - val_acc: 0.9627\n",
      "Epoch 2/10\n",
      "56/56 [==============================] - 67s - loss: 0.1586 - acc: 0.9873 - val_loss: 0.3421 - val_acc: 0.9724\n",
      "Epoch 3/10\n",
      "56/56 [==============================] - 67s - loss: 0.1373 - acc: 0.9894 - val_loss: 0.3059 - val_acc: 0.9779\n",
      "Epoch 4/10\n",
      "56/56 [==============================] - 67s - loss: 0.1289 - acc: 0.9902 - val_loss: 0.3006 - val_acc: 0.9779\n",
      "Epoch 5/10\n",
      "56/56 [==============================] - 67s - loss: 0.1235 - acc: 0.9916 - val_loss: 0.2539 - val_acc: 0.9807\n",
      "Epoch 6/10\n",
      "56/56 [==============================] - 67s - loss: 0.1151 - acc: 0.9908 - val_loss: 0.3194 - val_acc: 0.9793\n",
      "Epoch 7/10\n",
      "56/56 [==============================] - 67s - loss: 0.1092 - acc: 0.9912 - val_loss: 0.2485 - val_acc: 0.9834\n",
      "Epoch 8/10\n",
      "56/56 [==============================] - 67s - loss: 0.0630 - acc: 0.9961 - val_loss: 0.2647 - val_acc: 0.9820\n",
      "Epoch 9/10\n",
      "56/56 [==============================] - 67s - loss: 0.0672 - acc: 0.9955 - val_loss: 0.5424 - val_acc: 0.9613\n",
      "Epoch 10/10\n",
      "56/56 [==============================] - 68s - loss: 0.0814 - acc: 0.9941 - val_loss: 0.2168 - val_acc: 0.9866\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 11s - loss: 0.4340 - acc: 0.9844    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "camera_model('04')\n",
    "#for camera_num in camera_nums:\n",
    "#    camera_model(camera_num)\n",
    "sound_file = 'http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav'\n",
    "display(Audio(url=sound_file, autoplay=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06\n",
      "1980\n",
      "660\n",
      "1\n",
      "1\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:87: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:87: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_steps=11, epochs=10, steps_per_epoch=31, validation_data=<generator...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 43s - loss: 3.0078 - acc: 0.7744 - val_loss: 1.3141 - val_acc: 0.8950\n",
      "Epoch 2/10\n",
      "31/31 [==============================] - 43s - loss: 1.6639 - acc: 0.8721 - val_loss: 1.6702 - val_acc: 0.8688\n",
      "Epoch 3/10\n",
      "31/31 [==============================] - 43s - loss: 1.2823 - acc: 0.8975 - val_loss: 1.1514 - val_acc: 0.8702\n",
      "Epoch 4/10\n",
      "31/31 [==============================] - 43s - loss: 1.0098 - acc: 0.9088 - val_loss: 0.7606 - val_acc: 0.9296\n",
      "Epoch 5/10\n",
      "31/31 [==============================] - 43s - loss: 0.5432 - acc: 0.9498 - val_loss: 0.4482 - val_acc: 0.9503\n",
      "Epoch 6/10\n",
      "31/31 [==============================] - 43s - loss: 0.4739 - acc: 0.9544 - val_loss: 0.7983 - val_acc: 0.9240\n",
      "Epoch 7/10\n",
      "31/31 [==============================] - 43s - loss: 0.3694 - acc: 0.9612 - val_loss: 0.6351 - val_acc: 0.9378\n",
      "Epoch 8/10\n",
      "31/31 [==============================] - 43s - loss: 0.3036 - acc: 0.9657 - val_loss: 0.2700 - val_acc: 0.9627\n",
      "Epoch 9/10\n",
      "31/31 [==============================] - 43s - loss: 0.2895 - acc: 0.9682 - val_loss: 0.2103 - val_acc: 0.9655\n",
      "Epoch 10/10\n",
      "31/31 [==============================] - 43s - loss: 0.1365 - acc: 0.9834 - val_loss: 0.2624 - val_acc: 0.9691\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 11s - loss: 0.5789 - acc: 0.9414    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "camera_model('06')\n",
    "#for camera_num in camera_nums:\n",
    "#    camera_model(camera_num)\n",
    "sound_file = 'http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav'\n",
    "display(Audio(url=sound_file, autoplay=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08\n",
      "3478\n",
      "660\n",
      "1\n",
      "9\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:87: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:87: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_steps=11, epochs=10, steps_per_epoch=55, validation_data=<generator...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 74s - loss: 0.5653 - acc: 0.9573 - val_loss: 0.1279 - val_acc: 0.9890\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 66s - loss: 0.2005 - acc: 0.9849 - val_loss: 0.2565 - val_acc: 0.9820\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 66s - loss: 0.1859 - acc: 0.9879 - val_loss: 0.3130 - val_acc: 0.9793\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 66s - loss: 0.2098 - acc: 0.9851 - val_loss: 0.2674 - val_acc: 0.9807\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 67s - loss: 0.1701 - acc: 0.9886 - val_loss: 0.2738 - val_acc: 0.9807\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 67s - loss: 0.1362 - acc: 0.9915 - val_loss: 0.2282 - val_acc: 0.9807\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 67s - loss: 0.1242 - acc: 0.9919 - val_loss: 0.1918 - val_acc: 0.9834\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 67s - loss: 0.1420 - acc: 0.9902 - val_loss: 0.1781 - val_acc: 0.9890\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 67s - loss: 0.1259 - acc: 0.9922 - val_loss: 0.1948 - val_acc: 0.9876\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 67s - loss: 0.1259 - acc: 0.9922 - val_loss: 0.1863 - val_acc: 0.9866\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 11s - loss: 1.0100 - acc: 0.9762    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "camera_model('08')\n",
    "#for camera_num in camera_nums:\n",
    "#    camera_model(camera_num)\n",
    "sound_file = 'http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav'\n",
    "display(Audio(url=sound_file, autoplay=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "3726\n",
      "660\n",
      "1\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:87: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:87: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_steps=11, epochs=10, steps_per_epoch=59, validation_data=<generator...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "59/59 [==============================] - 77s - loss: 0.4008 - acc: 0.9685 - val_loss: 0.5981 - val_acc: 0.9613\n",
      "Epoch 2/10\n",
      "59/59 [==============================] - 70s - loss: 0.2066 - acc: 0.9849 - val_loss: 0.2132 - val_acc: 0.9848\n",
      "Epoch 3/10\n",
      "59/59 [==============================] - 70s - loss: 0.1449 - acc: 0.9897 - val_loss: 0.2017 - val_acc: 0.9848\n",
      "Epoch 4/10\n",
      "59/59 [==============================] - 70s - loss: 0.1334 - acc: 0.9907 - val_loss: 0.2438 - val_acc: 0.9807\n",
      "Epoch 5/10\n",
      "59/59 [==============================] - 70s - loss: 0.1385 - acc: 0.9897 - val_loss: 0.3317 - val_acc: 0.9793\n",
      "Epoch 6/10\n",
      "59/59 [==============================] - 70s - loss: 0.0929 - acc: 0.9934 - val_loss: 0.2942 - val_acc: 0.9807\n",
      "Epoch 7/10\n",
      "59/59 [==============================] - 70s - loss: 0.1068 - acc: 0.9926 - val_loss: 0.2242 - val_acc: 0.9848\n",
      "Epoch 8/10\n",
      "59/59 [==============================] - 70s - loss: 0.0991 - acc: 0.9931 - val_loss: 0.2415 - val_acc: 0.9834\n",
      "Epoch 9/10\n",
      "59/59 [==============================] - 70s - loss: 0.0580 - acc: 0.9958 - val_loss: 0.1342 - val_acc: 0.9917\n",
      "Epoch 10/10\n",
      "59/59 [==============================] - 70s - loss: 0.0589 - acc: 0.9955 - val_loss: 0.2222 - val_acc: 0.9852\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 11s - loss: 0.6261 - acc: 0.9691    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "camera_model('11')\n",
    "#for camera_num in camera_nums:\n",
    "#    camera_model(camera_num)\n",
    "sound_file = 'http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav'\n",
    "display(Audio(url=sound_file, autoplay=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "3952\n",
      "660\n",
      "1\n",
      "219\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:87: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:87: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_steps=11, epochs=10, steps_per_epoch=62, validation_data=<generator...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 83s - loss: 0.1150 - acc: 0.9884 - val_loss: 0.0457 - val_acc: 0.9959\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 73s - loss: 0.0657 - acc: 0.9947 - val_loss: 0.0376 - val_acc: 0.9972\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 73s - loss: 0.0122 - acc: 0.9992 - val_loss: 0.0391 - val_acc: 0.9972\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 73s - loss: 0.0122 - acc: 0.9992 - val_loss: 0.0391 - val_acc: 0.9972\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 73s - loss: 0.0122 - acc: 0.9992 - val_loss: 0.0391 - val_acc: 0.9972\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 73s - loss: 0.0162 - acc: 0.9990 - val_loss: 0.0391 - val_acc: 0.9972\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 73s - loss: 0.0122 - acc: 0.9992 - val_loss: 0.0391 - val_acc: 0.9972\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 73s - loss: 0.0122 - acc: 0.9992 - val_loss: 0.0560 - val_acc: 0.9959\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 73s - loss: 0.0122 - acc: 0.9992 - val_loss: 0.0391 - val_acc: 0.9972\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 74s - loss: 0.0122 - acc: 0.9992 - val_loss: 0.0597 - val_acc: 0.9960\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 11s - loss: 3.9082 - acc: 0.9989       \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "camera_model('15')\n",
    "#for camera_num in camera_nums:\n",
    "#    camera_model(camera_num)\n",
    "sound_file = 'http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav'\n",
    "display(Audio(url=sound_file, autoplay=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "2968\n",
      "660\n",
      "1\n",
      "3\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:87: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:87: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_steps=11, epochs=10, steps_per_epoch=47, validation_data=<generator...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 66s - loss: 0.9598 - acc: 0.9216 - val_loss: 1.5933 - val_acc: 0.8771\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 58s - loss: 0.6334 - acc: 0.9538 - val_loss: 1.4090 - val_acc: 0.9006\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 58s - loss: 0.4936 - acc: 0.9612 - val_loss: 0.6672 - val_acc: 0.9503\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 58s - loss: 0.3257 - acc: 0.9746 - val_loss: 0.7041 - val_acc: 0.9461\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 58s - loss: 0.3486 - acc: 0.9732 - val_loss: 0.5193 - val_acc: 0.9530\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 58s - loss: 0.3614 - acc: 0.9691 - val_loss: 0.7077 - val_acc: 0.9448\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 58s - loss: 0.2389 - acc: 0.9816 - val_loss: 2.4043 - val_acc: 0.8370\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 58s - loss: 0.2808 - acc: 0.9774 - val_loss: 0.6466 - val_acc: 0.9475\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 58s - loss: 0.2080 - acc: 0.9827 - val_loss: 0.6863 - val_acc: 0.9475\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 59s - loss: 0.2260 - acc: 0.9825 - val_loss: 0.6296 - val_acc: 0.9570\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 11s - loss: 1.1362 - acc: 0.9409    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "camera_model('23')\n",
    "#for camera_num in camera_nums:\n",
    "#    camera_model(camera_num)\n",
    "sound_file = 'http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav'\n",
    "display(Audio(url=sound_file, autoplay=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "3930\n",
      "660\n",
      "1\n",
      "109\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:87: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:87: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_steps=11, epochs=10, steps_per_epoch=62, validation_data=<generator...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 81s - loss: 2.2280 - acc: 0.8579 - val_loss: 0.1336 - val_acc: 0.9917\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 73s - loss: 0.0528 - acc: 0.9967 - val_loss: 0.1558 - val_acc: 0.9903\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 73s - loss: 0.0528 - acc: 0.9967 - val_loss: 0.1336 - val_acc: 0.9917\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 73s - loss: 0.0528 - acc: 0.9967 - val_loss: 0.1558 - val_acc: 0.9903\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 73s - loss: 0.1037 - acc: 0.9927 - val_loss: 0.1558 - val_acc: 0.9903\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 73s - loss: 0.0447 - acc: 0.9972 - val_loss: 0.1558 - val_acc: 0.9903\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 73s - loss: 0.0447 - acc: 0.9972 - val_loss: 0.1336 - val_acc: 0.9917\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 73s - loss: 0.0447 - acc: 0.9972 - val_loss: 0.1336 - val_acc: 0.9917\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 73s - loss: 0.0724 - acc: 0.9945 - val_loss: 0.1336 - val_acc: 0.9917\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 73s - loss: 0.0406 - acc: 0.9975 - val_loss: 0.1733 - val_acc: 0.9892\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 11s - loss: 13.8495 - acc: 0.9921    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "camera_model('39')\n",
    "#for camera_num in camera_nums:\n",
    "#    camera_model(camera_num)\n",
    "sound_file = 'http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav'\n",
    "display(Audio(url=sound_file, autoplay=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "3116\n",
      "660\n",
      "1\n",
      "6\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:87: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:87: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_steps=11, epochs=10, steps_per_epoch=49, validation_data=<generator...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 70s - loss: 1.0324 - acc: 0.9139 - val_loss: 0.8596 - val_acc: 0.9351\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 60s - loss: 0.5923 - acc: 0.9535 - val_loss: 0.8246 - val_acc: 0.9420\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 60s - loss: 0.3897 - acc: 0.9686 - val_loss: 0.7995 - val_acc: 0.9351\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 60s - loss: 0.3703 - acc: 0.9686 - val_loss: 0.5916 - val_acc: 0.9530\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 60s - loss: 0.3303 - acc: 0.9732 - val_loss: 0.8641 - val_acc: 0.9378\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 60s - loss: 0.2607 - acc: 0.9779 - val_loss: 0.7032 - val_acc: 0.9544\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 60s - loss: 0.2199 - acc: 0.9834 - val_loss: 0.5883 - val_acc: 0.9558\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 60s - loss: 0.1961 - acc: 0.9840 - val_loss: 0.8738 - val_acc: 0.9365\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 60s - loss: 0.1578 - acc: 0.9867 - val_loss: 0.7491 - val_acc: 0.9475\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 61s - loss: 0.1948 - acc: 0.9850 - val_loss: 0.7383 - val_acc: 0.9476\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 11s - loss: 1.6508 - acc: 0.9425    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "camera_model('52')\n",
    "#for camera_num in camera_nums:\n",
    "#    camera_model(camera_num)\n",
    "sound_file = 'http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav'\n",
    "display(Audio(url=sound_file, autoplay=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "3897\n",
      "660\n",
      "1\n",
      "65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:87: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:87: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_steps=11, epochs=10, steps_per_epoch=61, validation_data=<generator...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "61/61 [==============================] - 74s - loss: 0.2008 - acc: 0.9791 - val_loss: 0.2058 - val_acc: 0.9862\n",
      "Epoch 2/10\n",
      "61/61 [==============================] - 73s - loss: 0.0981 - acc: 0.9932 - val_loss: 0.2226 - val_acc: 0.9862\n",
      "Epoch 3/10\n",
      "61/61 [==============================] - 73s - loss: 0.0724 - acc: 0.9940 - val_loss: 0.2972 - val_acc: 0.9765\n",
      "Epoch 4/10\n",
      "61/61 [==============================] - 73s - loss: 0.0392 - acc: 0.9972 - val_loss: 0.5824 - val_acc: 0.9489\n",
      "Epoch 5/10\n",
      "61/61 [==============================] - 73s - loss: 0.0620 - acc: 0.9951 - val_loss: 0.2093 - val_acc: 0.9862\n",
      "Epoch 6/10\n",
      "61/61 [==============================] - 73s - loss: 0.0333 - acc: 0.9980 - val_loss: 0.2392 - val_acc: 0.9848\n",
      "Epoch 7/10\n",
      "61/61 [==============================] - 73s - loss: 0.0330 - acc: 0.9980 - val_loss: 0.1558 - val_acc: 0.9903\n",
      "Epoch 8/10\n",
      "61/61 [==============================] - 73s - loss: 0.0577 - acc: 0.9958 - val_loss: 0.1674 - val_acc: 0.9890\n",
      "Epoch 9/10\n",
      "61/61 [==============================] - 73s - loss: 0.0345 - acc: 0.9974 - val_loss: 0.1336 - val_acc: 0.9917\n",
      "Epoch 10/10\n",
      "61/61 [==============================] - 73s - loss: 0.0289 - acc: 0.9982 - val_loss: 0.1301 - val_acc: 0.9919\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 11s - loss: 8.9553 - acc: 0.9872    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "camera_model('59')\n",
    "#for camera_num in camera_nums:\n",
    "#    camera_model(camera_num)\n",
    "sound_file = 'http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav'\n",
    "display(Audio(url=sound_file, autoplay=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "2850\n",
      "660\n",
      "1\n",
      "3\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:87: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:87: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_steps=11, epochs=10, steps_per_epoch=45, validation_data=<generator...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 65s - loss: 1.3548 - acc: 0.8921 - val_loss: 1.1369 - val_acc: 0.9130\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - 56s - loss: 0.6096 - acc: 0.9519 - val_loss: 0.9668 - val_acc: 0.9254\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - 56s - loss: 0.4939 - acc: 0.9610 - val_loss: 0.7512 - val_acc: 0.9461\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - 57s - loss: 0.3846 - acc: 0.9680 - val_loss: 0.6682 - val_acc: 0.9475\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - 57s - loss: 0.3826 - acc: 0.9722 - val_loss: 0.9049 - val_acc: 0.9323\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - 57s - loss: 0.4085 - acc: 0.9685 - val_loss: 0.7241 - val_acc: 0.9448\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - 57s - loss: 0.2706 - acc: 0.9784 - val_loss: 0.6477 - val_acc: 0.9448\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - 57s - loss: 0.2609 - acc: 0.9796 - val_loss: 1.1673 - val_acc: 0.9130\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - 57s - loss: 0.1779 - acc: 0.9852 - val_loss: 0.6072 - val_acc: 0.9530\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - 57s - loss: 0.1570 - acc: 0.9877 - val_loss: 0.5848 - val_acc: 0.9583\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 11s - loss: 1.6256 - acc: 0.9222    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "camera_model('62')\n",
    "#for camera_num in camera_nums:\n",
    "#    camera_model(camera_num)\n",
    "sound_file = 'http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav'\n",
    "display(Audio(url=sound_file, autoplay=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "2563\n",
      "660\n",
      "1\n",
      "2\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:87: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:87: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_steps=11, epochs=10, steps_per_epoch=41, validation_data=<generator...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 59s - loss: 3.0431 - acc: 0.7939 - val_loss: 1.4268 - val_acc: 0.8743\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 52s - loss: 0.9821 - acc: 0.9216 - val_loss: 1.1973 - val_acc: 0.8964\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 52s - loss: 0.6592 - acc: 0.9456 - val_loss: 0.8035 - val_acc: 0.9378\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 52s - loss: 0.5110 - acc: 0.9593 - val_loss: 1.8300 - val_acc: 0.8439\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 52s - loss: 0.4508 - acc: 0.9639 - val_loss: 0.7323 - val_acc: 0.9406\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 52s - loss: 0.4021 - acc: 0.9688 - val_loss: 0.9255 - val_acc: 0.9254\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 52s - loss: 0.4580 - acc: 0.9680 - val_loss: 0.8610 - val_acc: 0.9420\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 52s - loss: 0.3557 - acc: 0.9731 - val_loss: 0.6777 - val_acc: 0.9489\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 52s - loss: 0.3269 - acc: 0.9752 - val_loss: 0.9775 - val_acc: 0.9199\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 53s - loss: 0.3143 - acc: 0.9753 - val_loss: 0.6981 - val_acc: 0.9489\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 11s - loss: 1.3556 - acc: 0.9216    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "camera_model('63')\n",
    "#for camera_num in camera_nums:\n",
    "#    camera_model(camera_num)\n",
    "sound_file = 'http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav'\n",
    "display(Audio(url=sound_file, autoplay=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "2527\n",
      "660\n",
      "1\n",
      "2\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:87: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:87: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_steps=11, epochs=10, steps_per_epoch=40, validation_data=<generator...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 52s - loss: 2.1104 - acc: 0.8248 - val_loss: 1.1562 - val_acc: 0.8812\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 52s - loss: 1.0250 - acc: 0.9097 - val_loss: 1.1841 - val_acc: 0.9033\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 52s - loss: 0.7592 - acc: 0.9341 - val_loss: 1.0986 - val_acc: 0.8798\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 52s - loss: 0.5143 - acc: 0.9551 - val_loss: 1.1906 - val_acc: 0.8798\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 51s - loss: 0.4331 - acc: 0.9581 - val_loss: 1.5175 - val_acc: 0.8619\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 52s - loss: 0.4604 - acc: 0.9564 - val_loss: 0.9729 - val_acc: 0.9227\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 52s - loss: 0.4608 - acc: 0.9609 - val_loss: 1.1534 - val_acc: 0.8978\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 52s - loss: 0.2839 - acc: 0.9772 - val_loss: 0.8884 - val_acc: 0.9171\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 52s - loss: 0.2965 - acc: 0.9744 - val_loss: 1.1053 - val_acc: 0.8854\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 52s - loss: 0.2280 - acc: 0.9770 - val_loss: 0.9728 - val_acc: 0.9220\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 11s - loss: 1.7550 - acc: 0.8849    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "camera_model('72')\n",
    "#for camera_num in camera_nums:\n",
    "#    camera_model(camera_num)\n",
    "sound_file = 'http://www.pacdv.com/sounds/interface_sound_effects/sound82.wav'\n",
    "display(Audio(url=sound_file, autoplay=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
